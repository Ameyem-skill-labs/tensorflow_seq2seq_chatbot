{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seq2seq.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "FnS-GXJOJOY2",
        "colab_type": "text"
      },
      "source": [
        "Tensorflow 1.4.0 is required.\n",
        "This is based on [NMT Tutorial](https://github.com/tensorflow/nmt)."
      ],
      "cell_type": "markdown"
    },
    {
      "metadata": {
        "id": "caxRbRVkDdhp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from __future__ import print_function\n",
        "from tensorflow.python.layers import core as layers_core\n",
        "from tensorflow.python.platform import gfile\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "\n",
        "## Note for me. You've summarized Seq2Seq at http://d.hatena.ne.jp/higepon/20171210/1512887715."
      ],
      "cell_type": "code",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g-ZP7_08WtPv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 3
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7b19e73c-ad56-4f45-9770-c8502ffa6235",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1513905860389,
          "user_tz": -540,
          "elapsed": 3204,
          "user": {
            "displayName": "Taro Minowa",
            "photoUrl": "//lh6.googleusercontent.com/-G-LK6tJKdI8/AAAAAAAAAAI/AAAAAAACNIM/dpIvfwO7Jmg/s50-c-k-no/photo.jpg",
            "userId": "107321843635318237808"
          }
        }
      },
      "source": [
        "tf.__version__\n",
        "!mkdir \"./saved_model2\"\n",
        "!mkdir \"./saved_model\"\n",
        "\n",
        "\n",
        "!ls -la ./saved_model2"
      ],
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘./saved_model2’: File exists\n",
            "mkdir: cannot create directory ‘./saved_model’: File exists\n",
            "total 12\n",
            "drwxr-xr-x  3 root root 4096 Dec 22 01:23 .\n",
            "drwxr-xr-x 13 2000 2000 4096 Dec 22 01:23 ..\n",
            "drwxr-xr-x  2 root root 4096 Dec 22 01:23 hige\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C16WwvYwGVBm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "source": [
        "# TODO\n",
        "# Make 2 models possible\n",
        "# Make them as methods\n",
        "# Change first part to use small hparams for debug\n",
        "# We could pass sequence_length to tf.nn.dynamic_rnn for better performance.\n",
        "# Maybe extract hparams\n",
        "# モデル どうやって reload するか？\n",
        "# support beam infer\n",
        "# attention default\n",
        "# model_path による reload が動いて得ない。\n",
        "\n",
        "test_hparams = tf.contrib.training.HParams(\n",
        "    batch_size=3,\n",
        "    encoder_length=5,\n",
        "    decoder_length=5,\n",
        "    num_units=6,\n",
        "    vocab_size=9,\n",
        "    embedding_size=8,\n",
        "    learning_rate = 0.01,\n",
        "    max_gradient_norm = 5.0,\n",
        "    beam_width =9,\n",
        "    use_attention = False,\n",
        "    num_train_steps = 150,\n",
        "    debug_verbose = False\n",
        ")\n",
        "\n",
        "real_hparams = tf.contrib.training.HParams(\n",
        "    batch_size=25, # of tweets should be devidable by batch_size\n",
        "    encoder_length=20, \n",
        "    decoder_length=20,\n",
        "    num_units=1024,\n",
        "    vocab_size=500,\n",
        "    embedding_size=256,\n",
        "    learning_rate = 0.01,\n",
        "    max_gradient_norm = 5.0,\n",
        "    beam_width =9,\n",
        "    use_attention = False,\n",
        "    num_train_steps = 100,\n",
        "    debug_verbose = True\n",
        ")\n",
        "\n",
        "# Model path\n",
        "model_path = \"./saved_model/twitter\"\n",
        "\n",
        "# Symbol for start decode process.\n",
        "tgt_sos_id = 0\n",
        "\n",
        "# Symbol for end of decode process.\n",
        "tgt_eos_id = 1\n",
        "\n",
        "pad_id = 2\n",
        "\n",
        "unk_id = 3"
      ],
      "cell_type": "code",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DFEYKvBwL3Nm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "source": [
        "# For debug purpose.\n",
        "tf.reset_default_graph()\n",
        "\n",
        "class ChatbotModel:\n",
        "  def __init__(self, sess, hparams, model_path, scope='ChatbotModel'):\n",
        "    self.sess = sess\n",
        "    # todo remove\n",
        "    self.hparams = hparams\n",
        "    \n",
        "    # todo\n",
        "    self.model_path = model_path\n",
        "    self.name = scope\n",
        "\n",
        "    self.encoder_inputs, encoder_outputs, encoder_state, embedding_encoder = self._build_encoder(hparams, scope)\n",
        "    self.decoder_inputs, self.decoder_lengths, self.replies, self.beam_replies, logits, self.infer_logits = self._build_decoder(hparams, embedding_encoder, encoder_state, encoder_outputs, scope)\n",
        "\n",
        "    self.reward = tf.placeholder(tf.float32, name=\"reward\")\n",
        "    self.target_labels, self.loss, self.global_step, self.train_op = self._build_optimizer(hparams, logits)\n",
        "    \n",
        "    # Initialize saver after model created\n",
        "    self.saver = tf.train.Saver(tf.global_variables())\n",
        "\n",
        "    ckpt = tf.train.get_checkpoint_state(self.model_path)\n",
        "    if ckpt:\n",
        "      last_model = ckpt.model_checkpoint_path\n",
        "      self.saver.restore(self.sess, last_model)\n",
        "      print(\"loaded \" + last_model)\n",
        "    else:\n",
        "      self.sess.run(tf.global_variables_initializer())\n",
        "      print(\"created fresh model.\")\n",
        "      \n",
        "  def train(self, encoder_inputs, target_labels, decoder_inputs, decoder_lengths):\n",
        "    feed_dict = {\n",
        "        self.encoder_inputs: encoder_inputs,\n",
        "        self.target_labels: target_labels,\n",
        "        self.decoder_inputs: decoder_inputs,\n",
        "        self.decoder_lengths: decoder_lengths,\n",
        "        # For normal Seq2Seq reward is always 1.\n",
        "        self.reward: 1.0 \n",
        "    }    \n",
        "    _, loss_value, global_step = self.sess.run([self.train_op, self.loss, self.global_step], feed_dict=feed_dict)\n",
        "    return loss_value, global_step\n",
        "\n",
        "  # How to implemen this\n",
        "  #  (1) Infer by training input.\n",
        "  #  (2) Get the output\n",
        "  #  (3) Pass the output to normal another Seq2Seq and calculate reward.\n",
        "  #  (4) train_with_rewards\n",
        "  #  (4) Then traning with the adjusted loss.  \n",
        "  def train_with_reward(self, standard_seq2seq_model, encoder_inputs, target_labels, decoder_inputs, decoder_lengths, dull_responses):\n",
        "    infered_replies = self.infer(encoder_inputs)\n",
        "    standard_seq2seq_encoder_inputs =[]\n",
        "    for reply in infered_replies:\n",
        "      if len(reply) <= self.hparams.encoder_length:\n",
        "        standard_seq2seq_encoder_inputs.append(np.append(reply, ([pad_id] * (self.hparams.encoder_length - len(reply)))))\n",
        "      else:\n",
        "        raise Exception(\"Infered reply is not suppose to be longer than encoder_input\")\n",
        "    standard_seq2seq_encoder_inputs = np.transpose(np.array(standard_seq2seq_encoder_inputs))\n",
        "    reward = standard_seq2seq_model.reward_ease_of_answering(standard_seq2seq_encoder_inputs, dull_responses)\n",
        "    print(reward)\n",
        "  \n",
        "  def infer(self, encoder_inputs):\n",
        "    inference_feed_dict = {\n",
        "        self.encoder_inputs: encoder_inputs,\n",
        "    }\n",
        "    replies = self.sess.run(self.replies, feed_dict=inference_feed_dict)\n",
        "    return replies\n",
        "  \n",
        "  def infer_beam_search(self, encoder_inputs):\n",
        "    inference_feed_dict = {\n",
        "        self.encoder_inputs: encoder_inputs,\n",
        "    }    \n",
        "    replies = self.sess.run(self.beam_replies, feed_dict=inference_feed_dict)\n",
        "    return replies\n",
        "  \n",
        "  ## todo model_path\n",
        "  def save(self):\n",
        "      self.saver.save(self.sess, \"{}/{}\".format(self.model_path, self.name), global_step=self.global_step)\n",
        "      \n",
        "  def log_prob(self, encoder_inputs, expected_output):\n",
        "    \"\"\"Return sum of log probability of given one specific expected_output for sencoder_inputs.\n",
        "\n",
        "    Args:\n",
        "        encoder_inputs: [encoder_length, batch_size], eg) tweets\n",
        "        expected_output: [1, decoder_length or less than decoder_length], eg) One reply.\n",
        "\n",
        "    Returns:\n",
        "        Return log probablity of expected output for given encoder inputs.\n",
        "        eg) sum of log probability of reply \"Good\" when given [\"How are you?\", \"What's up?\"]\n",
        "    \"\"\"\n",
        "    inference_feed_dict = {\n",
        "      self.encoder_inputs: encoder_inputs,\n",
        "    }\n",
        "    \n",
        "    # Logits\n",
        "    #   logits_value: [batch_size, actual_decoder_length, vocab_size]\n",
        "    logits_batch_value = self.sess.run(self.infer_logits, feed_dict=inference_feed_dict)\n",
        "\n",
        "    sum_p = []\n",
        "    # For each batch: [actual_decoder_length, vocab_size]\n",
        "    for logits in logits_batch_value:\n",
        "      p = 1\n",
        "      # Note that expected_output and logits don't always have same length, but zip takes care of the case.\n",
        "      for word_id, logit in zip(expected_output, logits):\n",
        "        # Apply softmax first, see definition of softmax.\n",
        "        norm = (self._softmax(logit))[word_id]\n",
        "        p *= norm\n",
        "      p = np.log(p)\n",
        "      sum_p.append(p)\n",
        "    ret = np.sum(sum_p) / len(sum_p)\n",
        "    return ret  \n",
        "  \n",
        "  def reward_ease_of_answering(self, encoder_inputs, expected_outputs):\n",
        "    \"\"\" Return reward for ease of answering. See Deep Reinforcement Learning for Dialogue Generation for more details.\n",
        "\n",
        "    Args:\n",
        "        encoder_inputs: [encoder_length, batch_size], eg) tweets\n",
        "        expected_outputs: [number of pre-defined dull responses, decoder_length or less than decoder_length]. eg) [[\"I'm\", \"Good\"], [\"fine\"]]\n",
        "\n",
        "    Returns:\n",
        "        Return reward for ease of answering.\n",
        "        Note that this can be calcualated by calling log_prob function for each dull response,\n",
        "        but this function is more efficient because this calculated the reward at once.\n",
        "    \"\"\"    \n",
        "    inference_feed_dict = {\n",
        "      self.encoder_inputs: encoder_inputs,\n",
        "    }\n",
        "    \n",
        "    # Logits\n",
        "    #   logits_value: [batch_size, actual_decoder_length, vocab_size]\n",
        "    logits_batch_value = self.sess.run(self.infer_logits, feed_dict=inference_feed_dict)\n",
        "\n",
        "    batch_sum_p = []\n",
        "    # For each batch: [actual_decoder_length, vocab_size]\n",
        "    for logits in logits_batch_value:\n",
        "      sum_p = []\n",
        "      for expected_output in expected_outputs:\n",
        "        p = 1\n",
        "        # Note that expected_output and logits don't always have same length, but zip takes care of the case.\n",
        "        for word_id, logit in zip(expected_output, logits):\n",
        "          # Apply softmax first, see definition of softmax.\n",
        "          norm = (self._softmax(logit))[word_id]\n",
        "          p *= norm\n",
        "        p = np.log(p) / len(expected_output)\n",
        "        sum_p.append(p)\n",
        "      one_batch_p = np.sum(sum_p)\n",
        "      batch_sum_p.append(one_batch_p)\n",
        "    ret = np.sum(batch_sum_p) / len(batch_sum_p)\n",
        "    return -ret  \n",
        "      \n",
        "    \n",
        "  @staticmethod\n",
        "  def _softmax(x):\n",
        "      return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "      \n",
        "  def _build_optimizer(self, hparams, logits):\n",
        "    # Target labels\n",
        "    #   As described in doc for sparse_softmax_cross_entropy_with_logits,\n",
        "    #   labels should be [batch_size, decoder_lengths] instead of [batch_size, decoder_lengths, vocab_size].\n",
        "    #   So labels should have indices instead of vocab_size classes.\n",
        "    target_labels = tf.placeholder(tf.int32, shape=(hparams.batch_size, hparams.decoder_length), name=\"target_labels\")\n",
        "\n",
        "    # Loss\n",
        "    crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "        labels=target_labels, logits=logits)\n",
        "\n",
        "    loss = tf.reduce_sum(crossent / tf.to_float(hparams.batch_size))\n",
        "    # Adjust loss with reward.\n",
        "    loss = tf.multiply(loss, self.reward)\n",
        "    \n",
        "    # Train\n",
        "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
        "\n",
        "    # Calculate and clip gradients\n",
        "    params = tf.trainable_variables()\n",
        "    gradients = tf.gradients(loss, params)\n",
        "    clipped_gradients, _ = tf.clip_by_global_norm(\n",
        "        gradients, hparams.max_gradient_norm)\n",
        "\n",
        "    # Optimization\n",
        "    optimizer = tf.train.AdamOptimizer(hparams.learning_rate)\n",
        "    train_op = optimizer.apply_gradients(\n",
        "        zip(clipped_gradients, params), global_step=global_step)\n",
        "    return target_labels, loss, global_step, train_op\n",
        "  \n",
        "  def _build_encoder(self, hparams, scope):\n",
        "    # Encoder\n",
        "    #   encoder_inputs: [encoder_length, batch_size]\n",
        "    #   This is time major where encoder_length comes first instead of batch_size.\n",
        "    encoder_inputs = tf.placeholder(tf.int32, shape=(hparams.encoder_length, hparams.batch_size), name=\"encoder_inputs\")\n",
        "    \n",
        "    # Embedding\n",
        "    #   We originally didn't share embbedding between encoder and decoder.\n",
        "    #   But now we share it. It makes much easier to calculate rewards.\n",
        "    #   Matrix for embedding: [vocab_size, embedding_size]\n",
        "    with tf.variable_scope(scope):\n",
        "      embedding_encoder = tf.get_variable(\"embedding_encoder\", [hparams.vocab_size, hparams.embedding_size])\n",
        "\n",
        "    # Look up embedding:\n",
        "    #   encoder_inputs: [encoder_length, batch_size]\n",
        "    #   encoder_emb_inputs: [encoder_length, batch_size, embedding_size]\n",
        "    encoder_emb_inputs = tf.nn.embedding_lookup(embedding_encoder, encoder_inputs)\n",
        "\n",
        "    # LSTM cell.\n",
        "    with tf.variable_scope(scope):\n",
        "      encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(hparams.num_units)\n",
        "\n",
        "    # Run Dynamic RNN\n",
        "    #   encoder_outputs: [encoder_length, batch_size, num_units]\n",
        "    #   encoder_state: [batch_size, num_units], this is final state of the cell for each batch.\n",
        "    with tf.variable_scope(scope):\n",
        "      encoder_outputs, encoder_state = tf.nn.dynamic_rnn(encoder_cell, encoder_emb_inputs, time_major=True, dtype=tf.float32)\n",
        "      \n",
        "    return encoder_inputs, encoder_outputs, encoder_state, embedding_encoder\n",
        "  \n",
        "  def _build_decoder(self, hparams, embedding_encoder, encoder_state, encoder_output, scope):\n",
        "    # Decoder input\n",
        "    #   decoder_inputs: [decoder_length, batch_size]\n",
        "    #   decoder_lengths: [batch_size]\n",
        "    #   This is grand truth target inputs for training.\n",
        "    decoder_inputs = tf.placeholder(tf.int32, shape=(hparams.decoder_length, hparams.batch_size), name=\"decoder_inputs\")\n",
        "    decoder_lengths = tf.placeholder(tf.int32, shape=(hparams.batch_size), name=\"decoder_lengths\")\n",
        "\n",
        "    # Look up embedding:\n",
        "    #   decoder_inputs: [decoder_length, batch_size]\n",
        "    #   decoder_emb_inp: [decoder_length, batch_size, embedding_size]\n",
        "    decoder_emb_inputs = tf.nn.embedding_lookup(embedding_encoder, decoder_inputs)   \n",
        "    \n",
        "    # https://stackoverflow.com/questions/39573188/output-projection-in-seq2seq-model-tensorflow\n",
        "    # Internally, a neural network operates on dense vectors of some size,\n",
        "    # often 256, 512 or 1024 floats (let's say 512 for here). \n",
        "    # But at the end it needs to predict a word from the vocabulary which is often much larger,\n",
        "    # e.g., 40000 words. Output projection is the final linear layer that converts (projects) from the internal representation to the larger one.\n",
        "    # So, for example, it can consist of a 512 x 40000 parameter matrix and a 40000 parameter for the bias vector.\n",
        "    projection_layer = layers_core.Dense(hparams.vocab_size, use_bias=False)\n",
        "    \n",
        "    helper = tf.contrib.seq2seq.TrainingHelper(decoder_emb_inputs, decoder_lengths, time_major=True)\n",
        "\n",
        "    # Decoder with helper:\n",
        "    #   decoder_emb_inputs: [decoder_length, batch_size, embedding_size]\n",
        "    #   decoder_length: [batch_size] vector, which represents each target sequence length.\n",
        "    decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(hparams.num_units)\n",
        "\n",
        "    if hparams.use_attention:\n",
        "      # Attention\n",
        "      # attention_states: [batch_size, max_time, num_units]\n",
        "      attention_states = tf.transpose(self.encoder_outputs, [1, 0, 2])\n",
        "\n",
        "      # Create an attention mechanism\n",
        "      attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
        "          hparams.num_units, attention_states,\n",
        "          memory_sequence_length=None)\n",
        "\n",
        "      decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
        "          decoder_cell, attention_mechanism,\n",
        "          attention_layer_size=hparams.num_units)\n",
        "\n",
        "      initial_state = decoder_cell.zero_state(hparams.batch_size, tf.float32).clone(cell_state=encoder_state)\n",
        "    else:\n",
        "      initial_state = encoder_state    \n",
        "      \n",
        "    # Decoder and decode\n",
        "    decoder = tf.contrib.seq2seq.BasicDecoder(\n",
        "        decoder_cell, helper, initial_state,\n",
        "        output_layer=projection_layer)\n",
        "\n",
        "    # Dynamic decoding\n",
        "    #   final_outputs.rnn_output: [batch_size, decoder_length, vocab_size], list of RNN state.\n",
        "    #   final_outputs.sample_id: [batch_size, decoder_length], list of argmax of rnn_output.\n",
        "    #   final_state: [batch_size, num_units], list of final state of RNN on decode process.\n",
        "    #   final_sequence_lengths: [batch_size], list of each decoded sequence. \n",
        "    final_outputs, _final_state, _final_sequence_lengths = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
        "\n",
        "    if hparams.debug_verbose:\n",
        "      print(\"rnn_output.shape=\", final_outputs.rnn_output.shape)\n",
        "      print(\"sample_id.shape=\", final_outputs.sample_id.shape)\n",
        "      print(\"final_state=\", _final_state)\n",
        "      print(\"final_sequence_lengths.shape=\", _final_sequence_lengths.shape)\n",
        "\n",
        "    logits = final_outputs.rnn_output    \n",
        "    \n",
        "    # Inference\n",
        "    inference_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
        "        embedding_encoder,\n",
        "        tf.fill([hparams.batch_size], tgt_sos_id), tgt_eos_id)\n",
        "\n",
        "    # Inference Decoder\n",
        "    inference_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
        "        decoder_cell, inference_helper, initial_state,\n",
        "        output_layer=projection_layer)\n",
        "\n",
        "    # len(infered_reply) is lte encoder_length, because we are targetting tweeet (140 for each tweet)\n",
        "    # Also by doing this, we can pass the reply to other seq2seq w/o shorten it.\n",
        "    maximum_iterations = hparams.encoder_length\n",
        "\n",
        "    # Dynamic decoding\n",
        "    outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
        "        inference_decoder, maximum_iterations=maximum_iterations)\n",
        "    replies = outputs.sample_id\n",
        "    \n",
        "    # We use infer_logits instead of logits when calculating log_prob, because infer_logits doesn't require decoder_lengths input.\n",
        "    infer_logits = outputs.rnn_output\n",
        "\n",
        "    # Beam Search\n",
        "    # Replicate encoder infos beam_width times\n",
        "    decoder_initial_state = tf.contrib.seq2seq.tile_batch(\n",
        "        initial_state, multiplier=hparams.beam_width)\n",
        "\n",
        "    # Define a beam-search decoder\n",
        "    inference_decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n",
        "            cell=decoder_cell,\n",
        "            embedding=embedding_encoder,\n",
        "            start_tokens=tf.fill([hparams.batch_size], tgt_sos_id),\n",
        "            end_token=tgt_eos_id,\n",
        "            initial_state=decoder_initial_state,\n",
        "            beam_width=hparams.beam_width,\n",
        "            output_layer=projection_layer,\n",
        "            length_penalty_weight=0.0)\n",
        "\n",
        "    # Dynamic decoding\n",
        "    beam_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
        "        inference_decoder, maximum_iterations=maximum_iterations)\n",
        "    beam_replies = beam_outputs.predicted_ids    \n",
        "\n",
        "    return decoder_inputs, decoder_lengths, replies, beam_replies, logits, infer_logits"
      ],
      "cell_type": "code",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DQg8kU-2Dr-q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "source": [
        "# Helper functions to test\n",
        "def make_test_training_data(hparams):\n",
        "  train_encoder_inputs = np.empty((hparams.encoder_length, hparams.batch_size), dtype=np.int)\n",
        "  training_target_labels = np.empty((hparams.batch_size, hparams.decoder_length), dtype=np.int)\n",
        "  training_decoder_inputs = np.empty((hparams.decoder_length, hparams.batch_size), dtype=np.int)\n",
        "\n",
        "  # We keep first tweet to validate inference.\n",
        "  first_tweet = None\n",
        "\n",
        "  for i in range(hparams.batch_size):\n",
        "    # Tweet\n",
        "    tweet = np.random.randint(low=0, high=hparams.vocab_size, size=hparams.encoder_length)\n",
        "    train_encoder_inputs[:, i] = tweet  \n",
        "  \n",
        "    # Reply\n",
        "    #   Note that low = 2, as 0 and 1 are reserved.\n",
        "    reply = np.random.randint(low=2, high=hparams.vocab_size, size=hparams.decoder_length - 1)\n",
        "  \n",
        "    training_target_label = np.concatenate((reply, np.array([tgt_eos_id])))\n",
        "    training_target_labels[i] = training_target_label\n",
        "  \n",
        "    training_decoder_input = np.concatenate(([tgt_sos_id], reply))\n",
        "    training_decoder_inputs[:, i] = training_decoder_input\n",
        "  \n",
        "    if i == 0:\n",
        "      first_tweet = tweet\n",
        "      if hparams.debug_verbose:\n",
        "        print(\"0th tweet={}\".format(tweet))\n",
        "        print(\"0th reply_with_eos_suffix={}\".format(training_target_label))\n",
        "        print(\"0th reply_with_sos_prefix={}\".format(training_decoder_input))\n",
        "\n",
        "    if hparams.debug_verbose:\n",
        "      print(\"Tweets\")\n",
        "      print(train_encoder_inputs)\n",
        "      print(\"Replies\")\n",
        "      print(training_target_labels)\n",
        "      print(training_decoder_inputs)\n",
        "  return first_tweet, train_encoder_inputs, training_target_labels, training_decoder_inputs\n",
        "\n",
        "def test_training(test_hparams, model):\n",
        "  print(\"==== training model ====\")\n",
        "  first_tweet, train_encoder_inputs, training_target_labels, training_decoder_inputs = make_test_training_data(test_hparams)\n",
        "  # Train\n",
        "  x = []\n",
        "  y = []\n",
        "  for i in range(test_hparams.num_train_steps):\n",
        "    loss_value, global_step = model.train(train_encoder_inputs, training_target_labels, training_decoder_inputs, np.ones((test_hparams.batch_size), dtype=int) * test_hparams.decoder_length)\n",
        "    if i % 5 == 0 and test_hparams.debug_verbose:\n",
        "      print('.', end='')\n",
        "\n",
        "    if i % 15 == 0:\n",
        "      model.save()\n",
        "      x.append(global_step)\n",
        "      y.append(loss_value)\n",
        "      if test_hparams.debug_verbose:\n",
        "        print(\"loss={} step={}\".format(loss_value, global_step))\n",
        "\n",
        "  inference_encoder_inputs = np.empty((test_hparams.encoder_length, test_hparams.batch_size), dtype=np.int)\n",
        "  for i in range(test_hparams.batch_size):\n",
        "    inference_encoder_inputs[:, i] = first_tweet\n",
        "\n",
        "\n",
        "  # testing \n",
        "  log_prob54 = model.log_prob(inference_encoder_inputs, np.array([5, 4]))\n",
        "  log_prob65 = model.log_prob(inference_encoder_inputs, np.array([6, 5]))\n",
        "  print(\"log_prob for 54\", log_prob54)\n",
        "  print(\"log_prob for 65\", log_prob65)\n",
        "\n",
        "  reward = model.reward_ease_of_answering(inference_encoder_inputs, np.array([[5], [6]]))\n",
        "  print(\"reward=\", reward)\n",
        "  \n",
        "  if test_hparams.debug_verbose:\n",
        "    print(inference_encoder_inputs)\n",
        "  replies = model.infer(inference_encoder_inputs)\n",
        "  print(\"Infered replies\", replies[0])\n",
        "  print(\"Expected replies\", training_target_labels[0])\n",
        "  \n",
        "  beam_replies = model.infer_beam_search(inference_encoder_inputs)\n",
        "  print(\"Infered replies candidate0\", beam_replies[0][:,0])\n",
        "  print(\"Infered replies candidate1\", beam_replies[0][:,1])\n",
        "\n",
        "  if test_hparams.debug_verbose:    \n",
        "    plt.plot(x, y, label=\"Loss\")\n",
        "    plt.plot()\n",
        "    plt.xlabel(\"Loss\")\n",
        "    plt.ylabel(\"steps\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "  \n",
        "def test_two_models_training():\n",
        "  first_tweet, train_encoder_inputs, training_target_labels, training_decoder_inputs = make_test_training_data(test_hparams)\n",
        "\n",
        "  graph1= tf.Graph()\n",
        "  graph2 = tf.Graph()\n",
        "\n",
        "  with graph1.as_default():\n",
        "    sess1 = tf.Session(graph=graph1)\n",
        "    model = ChatbotModel(sess1, test_hparams, model_path=\"./saved_model/hige\")\n",
        "    test_training(test_hparams, model)  \n",
        "\n",
        "  with graph2.as_default():\n",
        "    sess2 = tf.Session(graph=graph2)\n",
        "    model2 = ChatbotModel(sess2, test_hparams, model_path=\"./saved_model2/hige\")\n",
        "    test_training(test_hparams, model2)  \n",
        "    dull_responses = [[4, 6, 6], [5, 5]]\n",
        "    model2.train_with_reward(model, train_encoder_inputs, training_target_labels, training_decoder_inputs, np.ones((test_hparams.batch_size), dtype=int) * test_hparams.decoder_length, dull_responses)\n",
        "\n",
        "  \n"
      ],
      "cell_type": "code",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "St07WCfSBJoG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 10
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "00c3e2a4-a72b-4564-b4e7-90653339095d",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1513907245712,
          "user_tz": -540,
          "elapsed": 20096,
          "user": {
            "displayName": "Taro Minowa",
            "photoUrl": "//lh6.googleusercontent.com/-G-LK6tJKdI8/AAAAAAAAAAI/AAAAAAACNIM/dpIvfwO7Jmg/s50-c-k-no/photo.jpg",
            "userId": "107321843635318237808"
          }
        }
      },
      "source": [
        "! rm -rf ./saved_model\n",
        "! mkdir ./saved_model\n",
        "! rm -rf ./saved_model2\n",
        "! mkdir ./saved_model2\n",
        "\n",
        "# Fresh model\n",
        "test_two_models_training()\n",
        "\n",
        "# Saved model\n",
        "test_two_models_training()\n"
      ],
      "cell_type": "code",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created fresh model.\n",
            "==== training model ====\n",
            "log_prob for 54 -6.57202422497\n",
            "log_prob for 65 -14.7492445807\n",
            "reward= 16.8286383928\n",
            "Infered replies [4 8 7 2 1]\n",
            "Expected replies [4 8 7 2 1]\n",
            "Infered replies candidate0 [4 8 7 2 1]\n",
            "Infered replies candidate1 [4 5 7 2 1]\n",
            "created fresh model.\n",
            "==== training model ====\n",
            "log_prob for 54 -4.58980307162\n",
            "log_prob for 65 -13.3352072769\n",
            "reward= 6.37157379349\n",
            "Infered replies [5 2 8 2 1]\n",
            "Expected replies [5 2 8 2 1]\n",
            "Infered replies candidate0 [5 2 8 2 1]\n",
            "Infered replies candidate1 [5 2 8 8 2]\n",
            "8.04121222941\n",
            "INFO:tensorflow:Restoring parameters from ./saved_model/hige/ChatbotModel-136\n",
            "loaded ./saved_model/hige/ChatbotModel-136\n",
            "==== training model ====\n",
            "log_prob for 54 -17.5553426126\n",
            "log_prob for 65 -9.98088790466\n",
            "reward= 11.4933188261\n",
            "Infered replies [3 6 8 3 1]\n",
            "Expected replies [3 6 8 3 1]\n",
            "Infered replies candidate0 [3 6 8 3 1]\n",
            "Infered replies candidate1 [ 3  1 -1 -1 -1]\n",
            "INFO:tensorflow:Restoring parameters from ./saved_model2/hige/ChatbotModel-136\n",
            "loaded ./saved_model2/hige/ChatbotModel-136\n",
            "==== training model ====\n",
            "log_prob for 54 -10.0797947892\n",
            "log_prob for 65 -13.3140588737\n",
            "reward= 13.2327963857\n",
            "Infered replies [3 2 2 4 1]\n",
            "Expected replies [3 2 2 4 1]\n",
            "Infered replies candidate0 [3 2 2 4 1]\n",
            "Infered replies candidate1 [3 2 2 2 1]\n",
            "8.74459319039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SB627B3UGIac",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 3
            },
            {
              "item_id": 4
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "c7ceb1cb-791a-4be9-cd54-398ff7a251cb",
        "executionInfo": {
          "status": "error",
          "timestamp": 1513905811258,
          "user_tz": -540,
          "elapsed": 9784,
          "user": {
            "displayName": "Taro Minowa",
            "photoUrl": "//lh6.googleusercontent.com/-G-LK6tJKdI8/AAAAAAAAAAI/AAAAAAACNIM/dpIvfwO7Jmg/s50-c-k-no/photo.jpg",
            "userId": "107321843635318237808"
          }
        }
      },
      "source": [
        "!pip install pydrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python2.7/dist-packages\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python2.7/dist-packages (from pydrive)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (from pydrive)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python2.7/dist-packages (from pydrive)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->pydrive)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->pydrive)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->pydrive)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->pydrive)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0->pydrive)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client>=1.2->pydrive)\n",
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&prompt=select_account&response_type=code&client_id=32555940559.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ac80074ec5f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 1. Authenticate and create the PyDrive client.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mgauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleAuth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleCredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_application_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/colab/auth.pyc\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output)\u001b[0m\n\u001b[1;32m    118\u001b[0m   \"\"\"\n\u001b[1;32m    119\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_check_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0m_gcloud_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0m_install_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_check_adc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/google/colab/auth.pyc\u001b[0m in \u001b[0;36m_gcloud_login\u001b[0;34m(clear_output)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Enter verification code: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0mgcloud_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.pyc\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "kxeWpXO5FThm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "641d464b-eaad-46f9-aaf8-a81ba5028ea0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1513838024385,
          "user_tz": -540,
          "elapsed": 1800,
          "user": {
            "displayName": "Taro Minowa",
            "photoUrl": "//lh6.googleusercontent.com/-G-LK6tJKdI8/AAAAAAAAAAI/AAAAAAACNIM/dpIvfwO7Jmg/s50-c-k-no/photo.jpg",
            "userId": "107321843635318237808"
          }
        }
      },
      "source": [
        "def read_file_from_drive(file_name):\n",
        "  seq2seq_data_dir_id = \"146ZLldWXLDH0l9WbSUNFKi3nVK_HV0Sz\"\n",
        "  file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(seq2seq_data_dir_id)}).GetList()\n",
        "  found = [file for file in file_list if file['title'] == file_name]\n",
        "  if found != []:\n",
        "    downloaded = drive.CreateFile({'id': found[0]['id']})\n",
        "    return downloaded.GetContentString()\n",
        "  else:\n",
        "    raise ValueError(\"file {} not found.\".format(file_name))\n",
        "\n",
        "def read_vocabulary_drive(vocabulary_path):\n",
        "  rev_vocab = []\n",
        "  rev_vocab.extend(read_file_from_drive(vocabulary_path).splitlines())\n",
        "  print(rev_vocab)\n",
        "  rev_vocab = [line.strip() for line in rev_vocab]\n",
        "  vocab = dict([(x, y) for (y, x) in enumerate(rev_vocab)])\n",
        "  return vocab, rev_vocab  \n",
        "  \n",
        "print(read_vocabulary_drive('vocab.txt'))"
      ],
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[u'_GO', u'_EOS', u'_PAD', u'_UNK', u'\\uff01', u'\\u306e', u'\\u3066', u'0', u'\\u3001', u'\\u306b', u'\\u305f', u'\\u3067', u'\\u304c', u'\\u306f', u'\\u3092', u'\\u2026', u'\\u3057', u'\\u3002', u'\\u3082', u'#', u'\\u3067\\u3059', u'\\u307e\\u3059', u'\\u306d', u')', u'\\u3068', u'(', u'\\u306a', u'00', u'\\u306a\\u3044', u'\\u3093', u'www', u'\\u30fb', u'\\u304b\\u3089', u'\\u3060', u'\\u3088', u'\\u304b', u'\\uff1f', u'\\u307e\\u3067', u'rt', u'\\u3055\\u3093', u'\\u3054', u'\\u65e5', u'\\u62bd\\u9078', u'\\u30d5\\u30a9\\u30ed\\u30fc', u'/', u'\\u306e\\u3067', u'\\u4e2d', u'\\u3042\\u308a\\u304c\\u3068\\u3046', u'\\u6bce\\u65e5', u'\\u3059\\u308b', u'\\u671d', u'000', u'\\u03c9', u'\\u30fc', u'\\uff3c', u'\\uff0f', u'\\u540d', u'\\u69d8', u'\\u3054\\u3056\\u3044', u'\\u5f53\\u305f\\u308b', u'\\U0001f34b', u'\\u3063\\u3066', u'\\u304a', u'\\u307e\\u3057', u'\\u5fdc\\u52df', u'\\u300c', u'\\u3051\\u3069', u'\\uff06', u'\\u3053\\u306e', u'\\u6295\\u7a3f', u'\\u300d', u'w', u'\\u3042\\u3068', u'\\u305d\\u306e', u'\\u3046', u'\\u304f\\u3060\\u3055\\u3044', u'\\u3066\\u308b', u'\\u6c34', u'\\u7d50\\u679c', u'\\u3055', u'\\u301c', u'\\u307e\\u305f', u'\\u02d9', u'\\u5929\\u7136', u'\\u6311\\u6226', u'\\u4eba', u'\\u7b11', u'\\u52d5\\u753b', u'\\u79c1', u'\\u3068\\u304b', u'\\u5834', u'\\u6b8b\\u5ff5', u'\\u305f\\u3089', u'\\u30b1\\u30fc\\u30b9', u'\\u9ad8\\u3044', u'\\u3044\\u3044', u'\\u660e\\u65e5', u'\\u02d8', u'\\u30cf\\u30ba\\u30ec', u'\\u3084', u'\\u30c1\\u30e3\\u30ec\\u30f3\\u30b8', u'\\u65b0', u',', u'\\u30d7\\u30ec\\u30bc\\u30f3\\u30c8', u'\\u4eca', u'\\u308c', u'\\u5546\\u54c1', u'\\u30c6\\u30a3\\u30fc', u'\\u3059\\u3050', u'\\u4e00', u'\\uff08', u'\\u3044', u'\\u7cfb', u'\\u826f', u'\\u3061\\u3083\\u3093', u'\\u65b9', u'\\U0001f449', u'\\u306a\\u3063', u'\\uff09', u'\\U0001f453', u'\\u8a08', u'\\u610f\\u8b58', u'\\u702c', u'\\u793e\\u9577', u'\\u30e1\\u30c3\\u30bb\\u30fc\\u30b8', u'\\u305d\\u3046', u'\\u305d\\u308c', u'\\u3053\\u3068', u'\\u3060\\u3051\\u3069', u'\\U0001f622', u'\\u65e5\\u66ff\\u308f\\u308a', u'\\U0001f64f\\U0001f3fc', u'\\u2728\\uff01', u'\\u3042\\u3042', u'\\u305f\\u3044', u'\\u56de', u'\\u91d1', u'\\u3042\\u308b', u'\\u3044\\u308b', u'\\u3053\\u308c', u'\\u3088\\u3046', u'\\u4eca\\u65e5', u'-', u'\\u3054\\u89a7', u'\\u3084\\u3063', u'\\u30b9\\u30da\\u30b7\\u30e3\\u30eb', u'\\u3058\\u3083', u'\\u9ed2', u'\\u3059\\u304e', u'\\u76ee', u'\\u597d\\u304d', u'\\u3060\\u308d', u'\\u2022', u'\\u3082\\u3046', u'\\u308f', u'\\u308f\\u304b\\u308b', u'\\u304f\\u308c', u'\\u306a\\u308b', u'.', u'\\u304d', u'\\u5bdd', u':', u'\\u4f55', u'\\u6642', u'\\u6708', u'\\u3060\\u3063', u'\\u53ef\\u80fd', u'\\u3042\\u308a', u'\\u3053\\u3061\\u3089', u'\\u53ef\\u611b\\u3044', u'\\u3067\\u3082', u'\\xb4', u'\\u30d1\\u30f3\\u30c4', u'\\u3042', u'\\u3088\\u308a', u'\\u8a73\\u7d30', u'\\u3082\\u3066\\u306a\\u3057', u'\\u304a\\u9858\\u3044', u'\\u611f\\u3058', u'\\uff9f', u'\\u304f\\u308b', u'\\u3069', u'\\u306a\\u304f', u'\\u3067\\u304d\\u308b', u'\\u304f\\u3093', u'\\u306a\\u3089', u'\\u306e\\u3069\\u3054\\u3057', u'\\u30bf\\u30a4\\u30e0', u'\\u6ce2', u'\\u7460', u'\\u5b9f\\u65bd', u'\\u601d\\u3063', u'\\u4e00\\u3064', u'\\u3042\\u3063', u'\\u898b', u'\\u2661', u'\\u6765', u'\\u3057\\u304b', u'\\u2460', u'\\u2461', u'\\u671f\\u9593', u'\\u5408\\u8a08', u'\\u624b', u'`', u'\\u88fd\\u54c1', u'\\u6ef4', u'\\u6458\\u307f', u'\\u3044\\u308d\\u306f', u'\\u3059\\u3082\\u3082', u'\\u307f\\u304b\\u3093', u'\\u30ea\\u30cb\\u30e5\\u30fc\\u30a2\\u30eb', u'\\u306a\\u304b\\u3063', u'\\u51fa', u'\\u5186', u'\\u2190', u'\\u5927\\u4e08\\u592b', u'\\u307e\\u305b', u'\\u304b\\u3082', u'\\u53c2\\u52a0', u'\\u30a2\\u30ab\\u30a6\\u30f3\\u30c8', u'\\u307f', u'\\u6642\\u9593', u'\\u304f', u'\\u3070', u'\\u308c\\u308b', u'\\u2728', u'\\u65e5\\u672c', u'\\u3059', u'\\u7dbe', u'\\u3063', u'\\u524d', u'\\u0434', u'\\u601d\\u3044', u'ww', u'\\uff57', u'\\u6c17', u'\\u3060\\u3051', u'\\u3010', u'\\u30ad\\u30e3\\u30f3\\u30da\\u30fc\\u30f3', u'\\u304a\\u308a', u'\\u9df9', u'\\u3042\\u306a\\u305f', u'\\uff65', u'\\u306a\\u308a', u'\\u2192', u'\\u6295\\u7968', u'\\u30ea\\u30d7\\u30e9\\u30a4', u'\\u30b9\\u30ed\\u30c3\\u30c8', u'\\u3061\\u3083\\u3046', u'\\u3084\\u3064', u'\\u7684', u'\\u4ffa', u'\\ufe0f', u'\\u3067\\u3057', u'\\u305b', u'\\u3011', u'\\u5e74', u'\\u3048', u'\\uff5e', u'\\u3056\\u3044\\u307e\\u3059\\u3063', u'am', u'\\u8005', u'\\u304f\\u3089\\u3044', u'\\u30c4\\u30a4\\u30fc\\u30c8', u'\\u3067\\u3057\\u3087', u'\\u3069\\u3046', u'\\u307f\\u3093\\u306a', u\"'\", u'0000', u'\\u708e', u'\\u821e', u'\\u305d\\u3093\\u306a', u'\\u5165\\u308a', u'\\u30ea\\u30c4\\u30a4\\u30fc\\u30c8', u'\\u3060\\u304b\\u3089', u'\\u306a\\u3093\\u3066', u'\\u307e\\u3057\\u3087', u'\\u3088\\u308d\\u3057\\u304f', u'\\u5bb6\\u5eb7', u'\\u3082\\u3093', u'\\u753b\\u50cf', u'\\u884c\\u3063', u'cm', u'\\u306a\\u3069', u'\\u8a00\\u3063', u'\\u3061\\u3083\\u3063', u'\\u7e4b\\u304c\\u308a', u'\\u306a\\u3041', u'\\u7d76\\u8cdb', u'\\u767a\\u58f2', u'\\u3084\\u3081', u'...', u'\\u78ba\\u304b', u'\\U0001f495', u'\\u3088\\u304f', u'\\u884c\\u304f', u'\\u843d\\u3061', u'\\u81ea\\u5206', u'\\u4e07', u'\\u306e\\u306b', u'\\u3053\\u3053', u'\\u5468\\u5e74', u'\\u8a18\\u5ff5', u'\\u304a\\u5f85\\u3061', u'\\u6b21\\u56de', u'\\u76f4\\u7b46', u'\\u30b5\\u30a4\\u30f3', u'\\u30b0\\u30e9\\u30b9', u'\\u30b9\\u30da', u'\\u30b9\\u30da\\u30ad\\u30e3\\u30f3\\u30da\\u30fc\\u30f3', u'\\u98df\\u3079', u'\\u3082\\u3063\\u3068', u'\\u963f\\u90e8', u'\\u5bdb', u'\\u9854', u'\\u307f\\u305f\\u3044', u'\\u77e5\\u3063', u'\\u3078', u'\\u3067\\u308b', u'\\u307e\\u3060', u'\\u2200', u'\\u679a', u'\\ufe0e', u'\\u3053', u'\\u5f8c', u'\\u672c', u'\\u0648', u'o', u'\\u6b21', u'\\u3061\\u3087\\u3063\\u3068', u'\\u3068\\u3044\\u3046', u'\\u308f\\u305f\\u3057', u'\\u601d\\u3046', u'\\u3046\\u3093', u'\\u266a', u'\\u9811\\u5f35\\u3063', u'wwww', u'\\u307e\\u3058', u'\\u4e0a', u'\\u653e\\u6620', u'\\u4e0b\\u8a18', u'\\u751f\\u307e\\u308c', u'\\u3084\\u3093', u'\\u3067\\u304d', u'\\u6c34\\u6e90', u'\\u304a\\u3044\\u3057\\u3044', u'\\u7dcf\\u8a08', u'\\u8fd4\\u3063', u'\\u3053\\u3093\\u306a', u'\\u4e8c', u'\\u308f\\u304b\\u3089', u'\\u305f\\u304f', u'\\u8a71', u'\\u3093\\u3067', u'\\u3089\\u308c', u'\\u5fa1', u'\\u305d\\u3057\\u3066', u'\\u3064', u'\\u0325', u'\\u307b\\u3057\\u3044', u'\\u8a00\\u308f', u'\\u8003\\u3048', u'\\u305f\\u308a', u'\\u3061\\u3083', u'\\ua4aa', u'\\u3089', u'\\u3044\\u3063', u'jr', u'\\u81f4\\u3057', u'\\u4ed6', u'\\u6628\\u65e5', u'\\u300e', u'\\u300f', u'\\u9078\\u3093', u'\\u3044\\u3063\\u3071\\u3044', u'\\u5199\\u771f', u'\\u308a', u'\\u6226\\u56fd', u'\\u3057\\u304b\\u3082', u'\\u5165\\u3063', u'm', u'\\u540c\\u3058', u'\\u03b5', u'\\u4ecb\\u8b77', u'\\u3084\\u3070\\u3044', u'\\u6700\\u5f8c', u'\\u679c\\u5b9f', u'\\u30a8\\u30ad\\u30b9', u'\\u30e9\\u30b9\\u30c8\\u30b9\\u30d1\\u30fc\\u30c8', u'\\u79c0\\u5409', u'\\u5927', u'\\u7de8\\u96c6', u'\\u3057\\u3088', u'\\u4f5c\\u3063', u'\\u307e\\u3041', u'\\U0001f4a6', u'\\u5927\\u597d\\u304d', u'\\u3082\\u3089\\u3063', u'gt', u'lt', u'\\U0001f602', u'\\u3053\\u305d', u'\\u304d\\u3063\\u3068', u'\\u307e', u'\\uff57\\uff57\\uff57', u'\\u30ce', u'\\u5b09\\u3057\\u3044', u'\\u304a\\u3044', u'\\u591a\\u5206', u'\\u6570', u'(*', u'\\xba', u'\\u304a\\u8fce\\u3048', u'\\u5931\\u793c', u'\\u305e', u'\\u3046\\u308c\\u3057\\u3044', u'\\u3068\\u304d', u'\\u30c0\\u30e1', u'\\u3081\\u3063\\u3061\\u3083', u'\\u4ea4\\u63db', u'\\u4fe1\\u9577', u';', u'\\u307e\\u3044\\u308a', u'\\u305f\\u3060', u'\\u306b\\u3083', u'\\u3063\\u3059', u'\\u21db\\u2026', u'\\u306d\\u30fc', u'\\u5f53\\u9078', u'\\u4e00\\u7dd2', u'\\u306a\\u3093', u'\\u7121\\u7406', u'\\u541b', u'\\u5168\\u90e8', u'\\u8336', u'\\u3082\\u306e', u'\\u3042\\u306e', u'\\u5ea6', u'\\u5b50', u'\\uff01(', u'\\u3079', u'\\u4ed5\\u4e8b', u'\\u5bb6', u'\\u30b2\\u30fc\\u30e0', u'\\u672c\\u5f53', u'`)', u'\\u4eca\\u5e74', u'\\u25bc', u'\\u4e0b\\u3055\\u3044', u'\\u2606', u'\\u5206', u'\\u3042\\u30fc', u'\\u3048\\u3048', u'g', u'\\u306d\\u3047', u'\\u611f', u'\\u306a\\u30fc', u'\\u2605', u'\\U0001f607', u'\\u30c1\\u30a7\\u30c3\\u30af', u'\\u51fa\\u6765', u'\\u5ddd\\u8d8a', u'\\u3048\\u3063', u'\\u3055\\u3089\\u306b', u'!!', u'\\u7d50\\u69cb', u'\\u306f\\u3044', u'\\u75b2\\u308c', u'^', u'\\u65e8\\u307f', u'\\u8c4a\\u304b', u'\\u756a\\u8336', u'\\u3064\\u304b\\u3044', u'\\u5668', u'\\u624b\\u3056\\u308f\\u308a', u'\\u5473\\u308f\\u3048\\u308b', u'\\u4ed5\\u7acb\\u3066', u'\\u59ff', u'\\u8c6a\\u83ef', u'\\u7b11\\u3063', u'\\u666e\\u901a', u'\\u805e\\u3044', u'\\u52c9\\u5f37', u'(*\\xb4', u'\\u5148\\u751f', u'\\U0001f62d', u'wwwww', u'\\u8cb7\\u3063', u'\\u304b\\u3051', u'\\u8ab0', u'\\u65e9\\u304f', u'\\u62e1\\u6563', u'\\u270c', u'\\U0001f64f', u'\\u3064\\u3044', u'\\u884c\\u304d', u'\\u307e\\u307e', u'\\u3059\\u304d', u'\\u305d', u'\\u5e0c\\u671b']\n",
            "({u'gt': 398, u'\\u51fa\\u6765': 460, u'\\u6226\\u56fd': 377, u'\\u3010': 237, u'\\u5408\\u8a08': 201, u'\\u843d\\u3061': 296, u'\\u30ea\\u30d7\\u30e9\\u30a4': 246, u'\\u8c4a\\u304b': 470, u'\\u3067\\u3057': 253, u'\\u304a\\u8fce\\u3048': 412, u'\\u9811\\u5f35\\u3063': 335, u'\\u3067\\u3059': 20, u'0': 7, u'\\u304a\\u5f85\\u3061': 303, u'\\u65b9': 115, u'\\u5f53\\u305f\\u308b': 59, u'^': 468, u'\\u5e0c\\u671b': 499, u'\\u79c1': 88, u'\\u3082\\u3089\\u3063': 397, u'\\u91d1': 136, u'\\u5bdd': 160, u'\\u30b2\\u30fc\\u30e0': 443, u'\\u3060': 33, u'\\u3046\\u308c\\u3057\\u3044': 415, u'\\u3070': 223, u'\\u5e74': 256, u'\\u9df9': 240, u'\\u30fb': 31, u'_GO': 0, u'\\u7684': 250, u'\\u30d1\\u30f3\\u30c4': 172, u'\\ufe0f': 252, u'\\u75b2\\u308c': 467, u'\\u3059\\u3082\\u3082': 208, u'\\u679a': 321, u'\\u5b9f\\u65bd': 190, u'\\u98df\\u3079': 310, u'\\u3042\\u308a\\u304c\\u3068\\u3046': 47, u';': 421, u'\\u7dbe': 228, u'\\u307e\\u3057\\u3087': 276, u'\\u304b': 35, u'\\U0001f64f': 493, u'\\U0001f453': 119, u'\\u4f55': 162, u'\\u304f': 222, u'\\u305b': 254, u'\\u30a2\\u30ab\\u30a6\\u30f3\\u30c8': 219, u'\\u6765': 196, u'\\u306b': 9, u'\\u7121\\u7406': 431, u'\\u624b\\u3056\\u308f\\u308a': 474, u'\\u3067\\u3082': 170, u'\\u308f\\u304b\\u3089': 350, u'\\u308f\\u304b\\u308b': 155, u'\\u4ffa': 251, u'\\u3067\\u308b': 318, u'\\u62e1\\u6563': 491, u'\\u3082\\u3063\\u3068': 311, u'\\u305f\\u3089': 92, u'\\u898b': 194, u'\\u4e0a': 338, u'\\u3082\\u3066\\u306a\\u3057': 176, u'\\u3064': 357, u'\\u3059\\u304d': 497, u'\\uff9f': 179, u'\\u2026': 15, u'\\u30d5\\u30a9\\u30ed\\u30fc': 43, u'\\u81ea\\u5206': 297, u'\\u3066\\u308b': 76, u'\\u3060\\u3063': 165, u'\\u3059\\u308b': 49, u'\\u30e9\\u30b9\\u30c8\\u30b9\\u30d1\\u30fc\\u30c8': 388, u'\\u30b9\\u30da\\u30ad\\u30e3\\u30f3\\u30da\\u30fc\\u30f3': 309, u'\\u3046': 74, u'\\u79c0\\u5409': 389, u'\\u3053\\u3068': 127, u'\\u3053\\u306e': 68, u'\\u3067\\u304d': 343, u'g': 453, u'\\u3053\\u305d': 401, u'\\u3066': 6, u'\\u3053\\u3053': 300, u'\\u266a': 334, u'\\u5931\\u793c': 413, u'\\u3060\\u3051': 236, u'\\u679c\\u5b9f': 386, u'\\u7de8\\u96c6': 391, u'\\u3001': 8, u'\\u2605': 457, u'\\u884c\\u3063': 281, u'\\u3059\\u304e': 148, u'\\uff0f': 55, u'\\u3011': 255, u'\\u2190': 214, u'\\u306f': 13, u'\\u304f\\u3060\\u3055\\u3044': 75, u'\\u3059\\u3050': 108, u'\\uff1f': 36, u'\\u306a\\u3093\\u3066': 275, u'\\u7dcf\\u8a08': 346, u'\\u884c\\u304f': 295, u'\\u884c\\u304d': 495, u'\\u307f\\u304b\\u3093': 209, u'\\u3060\\u308d': 151, u'\\u3053\\u308c': 139, u'\\u30c1\\u30e3\\u30ec\\u30f3\\u30b8': 100, u'\\u4eba': 85, u'\\u3046\\u3093': 333, u'\\U0001f449': 116, u'\\u4eca': 104, u'\\u524d': 230, u'\\u666e\\u901a': 480, u'\\u304a\\u9858\\u3044': 177, u'\\u6642\\u9593': 221, u'\\u4e0b\\u3055\\u3044': 448, u'\\u5ddd\\u8d8a': 461, u'\\uff57\\uff57\\uff57': 404, u'\\u5b09\\u3057\\u3044': 406, u'\\u751f\\u307e\\u308c': 341, u'\\u78ba\\u304b': 292, u'\\u6ef4': 205, u'\\u4eca\\u5e74': 446, u'\\u65e5\\u66ff\\u308f\\u308a': 130, u'\\u306d\\u30fc': 427, u'\\u30c4\\u30a4\\u30fc\\u30c8': 263, u'\\u2200': 320, u'\\u52d5\\u753b': 87, u'\\U0001f62d': 485, u'\\u300c': 65, u'\\u305f\\u304f': 351, u'\\u653e\\u6620': 339, u'\\u305f\\u3044': 134, u'\\u301c': 80, u'\\u30bf\\u30a4\\u30e0': 187, u',': 102, u'lt': 399, u'\\u6c34': 77, u'\\uff08': 110, u'\\u7d50\\u69cb': 465, u'\\u7d76\\u8cdb': 288, u'\\u305f\\u3060': 423, u'\\u2460': 198, u'\\u5fdc\\u52df': 64, u'\\u304c': 12, u'\\u5929\\u7136': 83, u'\\uff5e': 258, u'\\u65e5': 41, u'\\u4e00\\u3064': 192, u'\\u5668': 473, u'\\u597d\\u304d': 150, u'\\u3053\\u3061\\u3089': 168, u'\\u53ef\\u611b\\u3044': 169, u'\\uff09': 118, u'\\u5bb6\\u5eb7': 278, u'\\u308c': 105, u'\\u6700\\u5f8c': 385, u'\\u7b11': 86, u'\\u2192': 244, u'`)': 445, u'\\u5186': 213, u'rt': 38, u'\\u30c0\\u30e1': 417, u\"'\": 267, u'\\u8a73\\u7d30': 175, u'\\u8ab0': 489, u'\\u5bb6': 442, u'\\u4ed5\\u7acb\\u3066': 476, u'\\u30b5\\u30a4\\u30f3': 306, u'\\u624b': 202, u'_UNK': 3, u'\\u9ad8\\u3044': 94, u'\\u5168\\u90e8': 433, u'\\u305f\\u308a': 362, u'\\u3057': 16, u'\\u3067': 11, u'\\u53ef\\u80fd': 166, u'\\u9ed2': 147, u'w': 71, u'\\u3060\\u3051\\u3069': 128, u'\\u30fc': 53, u'\\u306b\\u3083': 424, u'\\u3002': 17, u'\\u5206': 450, u'\\u6708': 164, u'\\ufe0e': 322, u'\\u3059': 227, u'\\U0001f495': 293, u'\\u3053\\u3093\\u306a': 348, u'\\u2022': 152, u'\\U0001f607': 458, u'\\u304d\\u3063\\u3068': 402, u'\\u2728': 225, u'\\u30ea\\u30c4\\u30a4\\u30fc\\u30c8': 273, u'\\u610f\\u8b58': 121, u'\\u3042': 173, u'\\u3044\\u308b': 138, u'\\u4e8c': 349, u'\\u5b50': 438, u'\\u8c6a\\u83ef': 478, u'\\u5bdb': 313, u'\\u306e\\u3069\\u3054\\u3057': 186, u'\\u5473\\u308f\\u3048\\u308b': 475, u'\\u304b\\u3051': 488, u'_EOS': 1, u'\\u3082': 18, u'\\u307e\\u307e': 496, u'\\u3058\\u3083': 146, u'\\u3044\\u3044': 95, u'\\u300d': 70, u'\\u3092': 14, u'\\u5199\\u771f': 375, u'\\u307e\\u3060': 319, u'\\u541b': 432, u'\\u307e\\u3067': 37, u'\\u307e\\u3058': 337, u'\\u307e\\u3059': 21, u'\\u307e\\u305b': 216, u'\\u5927': 390, u'\\u307e\\u305f': 81, u'\\u304b\\u3089': 32, u'\\ua4aa': 364, u'-': 142, u'\\u3044\\u3063': 366, u'\\u307e\\u3057': 63, u'\\u307e\\u3041': 394, u'(*\\xb4': 483, u'\\u308f\\u305f\\u3057': 331, u'\\U0001f34b': 60, u'\\u304d': 159, u'#': 19, u'\\u3089\\u308c': 354, u'\\u3051\\u3069': 66, u'\\u805e\\u3044': 481, u'\\u56de': 135, u'\\u306d': 22, u'\\u76ee': 149, u'\\u8a71': 352, u'\\u9078\\u3093': 373, u'\\u30b9\\u30ed\\u30c3\\u30c8': 247, u'\\u8003\\u3048': 361, u'\\u3057\\u304b': 197, u'\\u77e5\\u3063': 316, u'\\u3084\\u3081': 290, u'\\u3093': 29, u'\\u304a\\u3044': 407, u'\\u3084\\u3093': 342, u'(': 25, u'\\u306a\\u3093': 430, u'\\u03b5': 382, u'\\u306a\\u3089': 185, u'\\u306a\\u308a': 243, u'\\u306a\\u308b': 157, u'\\u81f4\\u3057': 368, u'\\u30d7\\u30ec\\u30bc\\u30f3\\u30c8': 103, u'\\u306a\\u30fc': 456, u'\\u6295\\u7a3f': 69, u'\\u3048': 257, u'\\u3055\\u3089\\u306b': 463, u'\\u304a\\u3044\\u3057\\u3044': 345, u'\\u601d\\u3044': 232, u'\\u601d\\u3046': 332, u'\\u305d\\u308c': 126, u'\\u7460': 189, u'\\u3067\\u3057\\u3087': 264, u'\\u53c2\\u52a0': 218, u'\\u3068': 24, u'\\u3064\\u3044': 494, u'\\u7d50\\u679c': 78, u'\\u3044\\u308d\\u306f': 207, u'\\u601d\\u3063': 191, u'\\u3078': 317, u'\\u7cfb': 112, u'\\u2728\\uff01': 132, u'\\u4e07': 298, u'\\u3088': 34, u'\\u62bd\\u9078': 42, u'\\u305d\\u3046': 125, u'\\u76f4\\u7b46': 305, u'\\u4fe1\\u9577': 420, u'\\u6b21': 328, u'\\u671d': 50, u'00': 27, u'\\u0325': 358, u'\\u304f\\u3089\\u3044': 262, u'\\u8fd4\\u3063': 347, u'\\u3064\\u304b\\u3044': 472, u'\\u305d\\u306e': 73, u'\\u4f5c\\u3063': 393, u'\\u5fa1': 355, u'\\u5148\\u751f': 484, u'\\u611f\\u3058': 178, u'jr': 367, u'\\u3057\\u3088': 392, u'ww': 233, u'\\u3053': 323, u'\\u306a\\u3069': 283, u'\\u304a\\u308a': 239, u'\\u306a\\u3063': 117, u'\\u3063': 229, u'\\u3084\\u3064': 249, u'\\u3084\\u3063': 144, u'\\u826f': 113, u'\\u306a\\u304f': 182, u'\\u306a\\u3044': 28, u'\\u4ecb\\u8b77': 383, u'\\u306a\\u3041': 287, u'\\u6b21\\u56de': 304, u'\\U0001f602': 400, u'cm': 282, u'\\u3089': 365, u'\\u3063\\u3066': 61, u'\\u7e4b\\u304c\\u308a': 286, u'\\u702c': 122, u'\\u5927\\u597d\\u304d': 396, u'\\U0001f622': 129, u'\\u672c': 325, u'\\u52c9\\u5f37': 482, u'.': 158, u'\\u3068\\u3044\\u3046': 330, u'\\u3063\\u3059': 425, u'\\u307e\\u3044\\u308a': 422, u'\\u65e9\\u304f': 490, u'\\u3054\\u3056\\u3044': 58, u'\\u753b\\u50cf': 280, u'\\uff3c': 54, u'\\u0434': 231, u'\\u65e5\\u672c': 226, u'\\u6642': 163, u'0000': 268, u'\\u540d': 56, u'\\u8336': 434, u'\\u660e\\u65e5': 96, u'\\u5468\\u5e74': 301, u'\\u793e\\u9577': 123, u'\\u30ea\\u30cb\\u30e5\\u30fc\\u30a2\\u30eb': 210, u'\\u6c34\\u6e90': 344, u'\\uff65': 242, u'\\u305e': 414, u'\\u307f\\u305f\\u3044': 315, u'\\u30c6\\u30a3\\u30fc': 107, u'\\u306e': 5, u'\\u6570': 409, u'\\u3044\\u3063\\u3071\\u3044': 374, u'\\u307b\\u3057\\u3044': 359, u'\\u30cf\\u30ba\\u30ec': 98, u'\\u540c\\u3058': 381, u'\\u307e': 403, u'\\u30a8\\u30ad\\u30b9': 387, u'\\u3060\\u304b\\u3089': 274, u'\\u5f8c': 324, u'\\u30ad\\u30e3\\u30f3\\u30da\\u30fc\\u30f3': 238, u'\\u708e': 269, u'\\u30b0\\u30e9\\u30b9': 307, u'\\u7b11\\u3063': 479, u'\\u6628\\u65e5': 370, u'\\u305d\\u3093\\u306a': 271, u'\\U0001f4a6': 395, u')': 23, u'\\u4e2d': 46, u'wwww': 336, u'\\u65b0': 101, u'\\u3084\\u3070\\u3044': 384, u'\\u4ed5\\u4e8b': 441, u'\\u0648': 326, u'\\u3069\\u3046': 265, u'\\u30b9\\u30da\\u30b7\\u30e3\\u30eb': 145, u'\\u304b\\u3082': 217, u'\\u30ce': 405, u'000': 51, u'\\u672c\\u5f53': 444, u'\\uff57': 234, u'\\u3042\\u306a\\u305f': 241, u'\\u69d8': 57, u'\\u2461': 199, u'\\u305d\\u3057\\u3066': 356, u'\\u3069': 181, u'\\uff01(': 439, u'\\u30b1\\u30fc\\u30b9': 93, u'\\u3079': 440, u'\\u9854': 314, u'\\u4e00': 109, u'\\u21db\\u2026': 426, u'\\u8cb7\\u3063': 487, u'\\u3042\\u3042': 133, u'\\uff06': 67, u'\\u8a08': 120, u'\\u6bce\\u65e5': 48, u'\\u308f': 154, u'\\u6b8b\\u5ff5': 91, u'\\u767a\\u58f2': 289, u'\\u3067\\u304d\\u308b': 183, u'\\u3042\\u3063': 193, u'\\u3042\\u306e': 436, u'\\u3042\\u3068': 72, u'\\u3055\\u3093': 39, u'\\u3088\\u308d\\u3057\\u304f': 277, u'\\u5834': 90, u'\\u4eca\\u65e5': 141, u'\\u3061\\u3083\\u3063': 285, u'...': 291, u'\\u5f53\\u9078': 428, u'\\u3044': 111, u'\\u03c9': 52, u'\\u270c': 492, u'(*': 410, u'\\u3054': 40, u'\\u3054\\u89a7': 143, u'\\u300e': 371, u'\\u5927\\u4e08\\u592b': 215, u'\\u8a00\\u3063': 284, u'\\u307f\\u3093\\u306a': 266, u'\\u3061\\u3083\\u3046': 248, u'wwwww': 486, u'\\u4e0b\\u8a18': 340, u'\\u306a\\u304b\\u3063': 211, u'\\uff01': 4, u'www': 30, u'\\u3084': 99, u'\\u756a\\u8336': 471, u'\\u8a00\\u308f': 360, u'\\u300f': 372, u'\\u5546\\u54c1': 106, u'\\u3048\\u3048': 452, u'\\u6c17': 235, u'\\u3093\\u3067': 353, u'\\u304f\\u308c': 156, u'\\u304f\\u308b': 180, u'/': 44, u'\\u3061\\u3083\\u3093': 114, u'_PAD': 2, u'\\xb4': 171, u'\\u3042\\u30fc': 451, u'\\u3048\\u3063': 462, u'\\u304f\\u3093': 184, u'\\u591a\\u5206': 408, u'\\u306f\\u3044': 466, u'\\u3042\\u308a': 167, u'\\u3042\\u308b': 137, u'\\u02d8': 97, u'\\u305f': 10, u'\\u30c1\\u30a7\\u30c3\\u30af': 459, u'o': 327, u'\\u51fa': 212, u'\\u307f': 220, u'!!': 464, u'\\u2606': 449, u'\\u4ed6': 369, u'\\u671f\\u9593': 200, u'\\u3088\\u308a': 174, u'\\u6295\\u7968': 245, u'\\u963f\\u90e8': 312, u'\\u821e': 270, u'\\u305d': 498, u'\\u3056\\u3044\\u307e\\u3059\\u3063': 259, u'\\u30b9\\u30da': 308, u':': 161, u'\\u4ea4\\u63db': 419, u'\\u3082\\u3046': 153, u'\\u304a': 62, u'\\u02d9': 82, u'\\u3061\\u3083': 363, u'\\u5165\\u308a': 272, u'\\u3082\\u306e': 435, u'\\u306a': 26, u'\\u3068\\u304b': 89, u'\\u88fd\\u54c1': 204, u'\\u6458\\u307f': 206, u'\\u3068\\u304d': 416, u'\\u30e1\\u30c3\\u30bb\\u30fc\\u30b8': 124, u'\\u59ff': 477, u'\\u8005': 261, u'm': 380, u'\\u308a': 376, u'am': 260, u'\\u306d\\u3047': 454, u'\\u5165\\u3063': 379, u'\\u3082\\u3093': 279, u'\\u611f': 455, u'\\u306e\\u306b': 299, u'\\u5ea6': 437, u'\\u3057\\u304b\\u3082': 378, u'\\u306e\\u3067': 45, u'\\xba': 411, u'\\u25bc': 447, u'\\u8a18\\u5ff5': 302, u'\\u3061\\u3087\\u3063\\u3068': 329, u'\\u3081\\u3063\\u3061\\u3083': 418, u'\\u65e8\\u307f': 469, u'\\u4e00\\u7dd2': 429, u'\\U0001f64f\\U0001f3fc': 131, u'\\u3055': 79, u'\\u3088\\u304f': 294, u'\\u6311\\u6226': 84, u'\\u3088\\u3046': 140, u'\\u308c\\u308b': 224, u'\\u2661': 195, u'\\u6ce2': 188, u'`': 203}, [u'_GO', u'_EOS', u'_PAD', u'_UNK', u'\\uff01', u'\\u306e', u'\\u3066', u'0', u'\\u3001', u'\\u306b', u'\\u305f', u'\\u3067', u'\\u304c', u'\\u306f', u'\\u3092', u'\\u2026', u'\\u3057', u'\\u3002', u'\\u3082', u'#', u'\\u3067\\u3059', u'\\u307e\\u3059', u'\\u306d', u')', u'\\u3068', u'(', u'\\u306a', u'00', u'\\u306a\\u3044', u'\\u3093', u'www', u'\\u30fb', u'\\u304b\\u3089', u'\\u3060', u'\\u3088', u'\\u304b', u'\\uff1f', u'\\u307e\\u3067', u'rt', u'\\u3055\\u3093', u'\\u3054', u'\\u65e5', u'\\u62bd\\u9078', u'\\u30d5\\u30a9\\u30ed\\u30fc', u'/', u'\\u306e\\u3067', u'\\u4e2d', u'\\u3042\\u308a\\u304c\\u3068\\u3046', u'\\u6bce\\u65e5', u'\\u3059\\u308b', u'\\u671d', u'000', u'\\u03c9', u'\\u30fc', u'\\uff3c', u'\\uff0f', u'\\u540d', u'\\u69d8', u'\\u3054\\u3056\\u3044', u'\\u5f53\\u305f\\u308b', u'\\U0001f34b', u'\\u3063\\u3066', u'\\u304a', u'\\u307e\\u3057', u'\\u5fdc\\u52df', u'\\u300c', u'\\u3051\\u3069', u'\\uff06', u'\\u3053\\u306e', u'\\u6295\\u7a3f', u'\\u300d', u'w', u'\\u3042\\u3068', u'\\u305d\\u306e', u'\\u3046', u'\\u304f\\u3060\\u3055\\u3044', u'\\u3066\\u308b', u'\\u6c34', u'\\u7d50\\u679c', u'\\u3055', u'\\u301c', u'\\u307e\\u305f', u'\\u02d9', u'\\u5929\\u7136', u'\\u6311\\u6226', u'\\u4eba', u'\\u7b11', u'\\u52d5\\u753b', u'\\u79c1', u'\\u3068\\u304b', u'\\u5834', u'\\u6b8b\\u5ff5', u'\\u305f\\u3089', u'\\u30b1\\u30fc\\u30b9', u'\\u9ad8\\u3044', u'\\u3044\\u3044', u'\\u660e\\u65e5', u'\\u02d8', u'\\u30cf\\u30ba\\u30ec', u'\\u3084', u'\\u30c1\\u30e3\\u30ec\\u30f3\\u30b8', u'\\u65b0', u',', u'\\u30d7\\u30ec\\u30bc\\u30f3\\u30c8', u'\\u4eca', u'\\u308c', u'\\u5546\\u54c1', u'\\u30c6\\u30a3\\u30fc', u'\\u3059\\u3050', u'\\u4e00', u'\\uff08', u'\\u3044', u'\\u7cfb', u'\\u826f', u'\\u3061\\u3083\\u3093', u'\\u65b9', u'\\U0001f449', u'\\u306a\\u3063', u'\\uff09', u'\\U0001f453', u'\\u8a08', u'\\u610f\\u8b58', u'\\u702c', u'\\u793e\\u9577', u'\\u30e1\\u30c3\\u30bb\\u30fc\\u30b8', u'\\u305d\\u3046', u'\\u305d\\u308c', u'\\u3053\\u3068', u'\\u3060\\u3051\\u3069', u'\\U0001f622', u'\\u65e5\\u66ff\\u308f\\u308a', u'\\U0001f64f\\U0001f3fc', u'\\u2728\\uff01', u'\\u3042\\u3042', u'\\u305f\\u3044', u'\\u56de', u'\\u91d1', u'\\u3042\\u308b', u'\\u3044\\u308b', u'\\u3053\\u308c', u'\\u3088\\u3046', u'\\u4eca\\u65e5', u'-', u'\\u3054\\u89a7', u'\\u3084\\u3063', u'\\u30b9\\u30da\\u30b7\\u30e3\\u30eb', u'\\u3058\\u3083', u'\\u9ed2', u'\\u3059\\u304e', u'\\u76ee', u'\\u597d\\u304d', u'\\u3060\\u308d', u'\\u2022', u'\\u3082\\u3046', u'\\u308f', u'\\u308f\\u304b\\u308b', u'\\u304f\\u308c', u'\\u306a\\u308b', u'.', u'\\u304d', u'\\u5bdd', u':', u'\\u4f55', u'\\u6642', u'\\u6708', u'\\u3060\\u3063', u'\\u53ef\\u80fd', u'\\u3042\\u308a', u'\\u3053\\u3061\\u3089', u'\\u53ef\\u611b\\u3044', u'\\u3067\\u3082', u'\\xb4', u'\\u30d1\\u30f3\\u30c4', u'\\u3042', u'\\u3088\\u308a', u'\\u8a73\\u7d30', u'\\u3082\\u3066\\u306a\\u3057', u'\\u304a\\u9858\\u3044', u'\\u611f\\u3058', u'\\uff9f', u'\\u304f\\u308b', u'\\u3069', u'\\u306a\\u304f', u'\\u3067\\u304d\\u308b', u'\\u304f\\u3093', u'\\u306a\\u3089', u'\\u306e\\u3069\\u3054\\u3057', u'\\u30bf\\u30a4\\u30e0', u'\\u6ce2', u'\\u7460', u'\\u5b9f\\u65bd', u'\\u601d\\u3063', u'\\u4e00\\u3064', u'\\u3042\\u3063', u'\\u898b', u'\\u2661', u'\\u6765', u'\\u3057\\u304b', u'\\u2460', u'\\u2461', u'\\u671f\\u9593', u'\\u5408\\u8a08', u'\\u624b', u'`', u'\\u88fd\\u54c1', u'\\u6ef4', u'\\u6458\\u307f', u'\\u3044\\u308d\\u306f', u'\\u3059\\u3082\\u3082', u'\\u307f\\u304b\\u3093', u'\\u30ea\\u30cb\\u30e5\\u30fc\\u30a2\\u30eb', u'\\u306a\\u304b\\u3063', u'\\u51fa', u'\\u5186', u'\\u2190', u'\\u5927\\u4e08\\u592b', u'\\u307e\\u305b', u'\\u304b\\u3082', u'\\u53c2\\u52a0', u'\\u30a2\\u30ab\\u30a6\\u30f3\\u30c8', u'\\u307f', u'\\u6642\\u9593', u'\\u304f', u'\\u3070', u'\\u308c\\u308b', u'\\u2728', u'\\u65e5\\u672c', u'\\u3059', u'\\u7dbe', u'\\u3063', u'\\u524d', u'\\u0434', u'\\u601d\\u3044', u'ww', u'\\uff57', u'\\u6c17', u'\\u3060\\u3051', u'\\u3010', u'\\u30ad\\u30e3\\u30f3\\u30da\\u30fc\\u30f3', u'\\u304a\\u308a', u'\\u9df9', u'\\u3042\\u306a\\u305f', u'\\uff65', u'\\u306a\\u308a', u'\\u2192', u'\\u6295\\u7968', u'\\u30ea\\u30d7\\u30e9\\u30a4', u'\\u30b9\\u30ed\\u30c3\\u30c8', u'\\u3061\\u3083\\u3046', u'\\u3084\\u3064', u'\\u7684', u'\\u4ffa', u'\\ufe0f', u'\\u3067\\u3057', u'\\u305b', u'\\u3011', u'\\u5e74', u'\\u3048', u'\\uff5e', u'\\u3056\\u3044\\u307e\\u3059\\u3063', u'am', u'\\u8005', u'\\u304f\\u3089\\u3044', u'\\u30c4\\u30a4\\u30fc\\u30c8', u'\\u3067\\u3057\\u3087', u'\\u3069\\u3046', u'\\u307f\\u3093\\u306a', u\"'\", u'0000', u'\\u708e', u'\\u821e', u'\\u305d\\u3093\\u306a', u'\\u5165\\u308a', u'\\u30ea\\u30c4\\u30a4\\u30fc\\u30c8', u'\\u3060\\u304b\\u3089', u'\\u306a\\u3093\\u3066', u'\\u307e\\u3057\\u3087', u'\\u3088\\u308d\\u3057\\u304f', u'\\u5bb6\\u5eb7', u'\\u3082\\u3093', u'\\u753b\\u50cf', u'\\u884c\\u3063', u'cm', u'\\u306a\\u3069', u'\\u8a00\\u3063', u'\\u3061\\u3083\\u3063', u'\\u7e4b\\u304c\\u308a', u'\\u306a\\u3041', u'\\u7d76\\u8cdb', u'\\u767a\\u58f2', u'\\u3084\\u3081', u'...', u'\\u78ba\\u304b', u'\\U0001f495', u'\\u3088\\u304f', u'\\u884c\\u304f', u'\\u843d\\u3061', u'\\u81ea\\u5206', u'\\u4e07', u'\\u306e\\u306b', u'\\u3053\\u3053', u'\\u5468\\u5e74', u'\\u8a18\\u5ff5', u'\\u304a\\u5f85\\u3061', u'\\u6b21\\u56de', u'\\u76f4\\u7b46', u'\\u30b5\\u30a4\\u30f3', u'\\u30b0\\u30e9\\u30b9', u'\\u30b9\\u30da', u'\\u30b9\\u30da\\u30ad\\u30e3\\u30f3\\u30da\\u30fc\\u30f3', u'\\u98df\\u3079', u'\\u3082\\u3063\\u3068', u'\\u963f\\u90e8', u'\\u5bdb', u'\\u9854', u'\\u307f\\u305f\\u3044', u'\\u77e5\\u3063', u'\\u3078', u'\\u3067\\u308b', u'\\u307e\\u3060', u'\\u2200', u'\\u679a', u'\\ufe0e', u'\\u3053', u'\\u5f8c', u'\\u672c', u'\\u0648', u'o', u'\\u6b21', u'\\u3061\\u3087\\u3063\\u3068', u'\\u3068\\u3044\\u3046', u'\\u308f\\u305f\\u3057', u'\\u601d\\u3046', u'\\u3046\\u3093', u'\\u266a', u'\\u9811\\u5f35\\u3063', u'wwww', u'\\u307e\\u3058', u'\\u4e0a', u'\\u653e\\u6620', u'\\u4e0b\\u8a18', u'\\u751f\\u307e\\u308c', u'\\u3084\\u3093', u'\\u3067\\u304d', u'\\u6c34\\u6e90', u'\\u304a\\u3044\\u3057\\u3044', u'\\u7dcf\\u8a08', u'\\u8fd4\\u3063', u'\\u3053\\u3093\\u306a', u'\\u4e8c', u'\\u308f\\u304b\\u3089', u'\\u305f\\u304f', u'\\u8a71', u'\\u3093\\u3067', u'\\u3089\\u308c', u'\\u5fa1', u'\\u305d\\u3057\\u3066', u'\\u3064', u'\\u0325', u'\\u307b\\u3057\\u3044', u'\\u8a00\\u308f', u'\\u8003\\u3048', u'\\u305f\\u308a', u'\\u3061\\u3083', u'\\ua4aa', u'\\u3089', u'\\u3044\\u3063', u'jr', u'\\u81f4\\u3057', u'\\u4ed6', u'\\u6628\\u65e5', u'\\u300e', u'\\u300f', u'\\u9078\\u3093', u'\\u3044\\u3063\\u3071\\u3044', u'\\u5199\\u771f', u'\\u308a', u'\\u6226\\u56fd', u'\\u3057\\u304b\\u3082', u'\\u5165\\u3063', u'm', u'\\u540c\\u3058', u'\\u03b5', u'\\u4ecb\\u8b77', u'\\u3084\\u3070\\u3044', u'\\u6700\\u5f8c', u'\\u679c\\u5b9f', u'\\u30a8\\u30ad\\u30b9', u'\\u30e9\\u30b9\\u30c8\\u30b9\\u30d1\\u30fc\\u30c8', u'\\u79c0\\u5409', u'\\u5927', u'\\u7de8\\u96c6', u'\\u3057\\u3088', u'\\u4f5c\\u3063', u'\\u307e\\u3041', u'\\U0001f4a6', u'\\u5927\\u597d\\u304d', u'\\u3082\\u3089\\u3063', u'gt', u'lt', u'\\U0001f602', u'\\u3053\\u305d', u'\\u304d\\u3063\\u3068', u'\\u307e', u'\\uff57\\uff57\\uff57', u'\\u30ce', u'\\u5b09\\u3057\\u3044', u'\\u304a\\u3044', u'\\u591a\\u5206', u'\\u6570', u'(*', u'\\xba', u'\\u304a\\u8fce\\u3048', u'\\u5931\\u793c', u'\\u305e', u'\\u3046\\u308c\\u3057\\u3044', u'\\u3068\\u304d', u'\\u30c0\\u30e1', u'\\u3081\\u3063\\u3061\\u3083', u'\\u4ea4\\u63db', u'\\u4fe1\\u9577', u';', u'\\u307e\\u3044\\u308a', u'\\u305f\\u3060', u'\\u306b\\u3083', u'\\u3063\\u3059', u'\\u21db\\u2026', u'\\u306d\\u30fc', u'\\u5f53\\u9078', u'\\u4e00\\u7dd2', u'\\u306a\\u3093', u'\\u7121\\u7406', u'\\u541b', u'\\u5168\\u90e8', u'\\u8336', u'\\u3082\\u306e', u'\\u3042\\u306e', u'\\u5ea6', u'\\u5b50', u'\\uff01(', u'\\u3079', u'\\u4ed5\\u4e8b', u'\\u5bb6', u'\\u30b2\\u30fc\\u30e0', u'\\u672c\\u5f53', u'`)', u'\\u4eca\\u5e74', u'\\u25bc', u'\\u4e0b\\u3055\\u3044', u'\\u2606', u'\\u5206', u'\\u3042\\u30fc', u'\\u3048\\u3048', u'g', u'\\u306d\\u3047', u'\\u611f', u'\\u306a\\u30fc', u'\\u2605', u'\\U0001f607', u'\\u30c1\\u30a7\\u30c3\\u30af', u'\\u51fa\\u6765', u'\\u5ddd\\u8d8a', u'\\u3048\\u3063', u'\\u3055\\u3089\\u306b', u'!!', u'\\u7d50\\u69cb', u'\\u306f\\u3044', u'\\u75b2\\u308c', u'^', u'\\u65e8\\u307f', u'\\u8c4a\\u304b', u'\\u756a\\u8336', u'\\u3064\\u304b\\u3044', u'\\u5668', u'\\u624b\\u3056\\u308f\\u308a', u'\\u5473\\u308f\\u3048\\u308b', u'\\u4ed5\\u7acb\\u3066', u'\\u59ff', u'\\u8c6a\\u83ef', u'\\u7b11\\u3063', u'\\u666e\\u901a', u'\\u805e\\u3044', u'\\u52c9\\u5f37', u'(*\\xb4', u'\\u5148\\u751f', u'\\U0001f62d', u'wwwww', u'\\u8cb7\\u3063', u'\\u304b\\u3051', u'\\u8ab0', u'\\u65e9\\u304f', u'\\u62e1\\u6563', u'\\u270c', u'\\U0001f64f', u'\\u3064\\u3044', u'\\u884c\\u304d', u'\\u307e\\u307e', u'\\u3059\\u304d', u'\\u305d', u'\\u5e0c\\u671b'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_Np6GIJATTGg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 2
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "15fe5144-a716-4b7a-9753-779efe5b0b1c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1513838034082,
          "user_tz": -540,
          "elapsed": 2967,
          "user": {
            "displayName": "Taro Minowa",
            "photoUrl": "//lh6.googleusercontent.com/-G-LK6tJKdI8/AAAAAAAAAAI/AAAAAAACNIM/dpIvfwO7Jmg/s50-c-k-no/photo.jpg",
            "userId": "107321843635318237808"
          }
        }
      },
      "source": [
        "def read_training_data_from_drive(file_name, max_line_len, pad_value):\n",
        "  ret = []\n",
        "  for line in read_file_from_drive(file_name).splitlines():\n",
        "    # padding\n",
        "    ids = [int(x) for x in line.split()]\n",
        "    if len(ids) > max_line_len:\n",
        "      ids = ids[:max_line_len]\n",
        "    else:\n",
        "      ids.extend([pad_value] * (max_line_len - len(ids)))\n",
        "    ret.append(ids)\n",
        "  return ret\n",
        "\n",
        "def words_to_ids(words, vocab):\n",
        "  ids = []\n",
        "  for word in words:\n",
        "    if word in vocab:\n",
        "      ids.append(vocab[word])\n",
        "    else:\n",
        "      ids.append(unk_id)\n",
        "  return ids\n",
        "\n",
        "def ids_to_words(ids, rev_vocab):\n",
        "  words = \"\"\n",
        "  for id in ids:\n",
        "    words += rev_vocab[id]\n",
        "  return words\n",
        "# For replies, we use decoder_lenght - 1, because we need to add eos/sos.\n",
        "replies = read_training_data_from_drive('tweets_train_dec_idx.txt', real_hparams.decoder_length - 1, pad_id)\n",
        "tweets = read_training_data_from_drive('tweets_train_enc_idx.txt', real_hparams.encoder_length, pad_id)\n",
        "print(\"tweets_shape=\", len(tweets))\n",
        "\n",
        "vocab, rev_vocab = read_vocabulary_drive('vocab.txt')\n",
        "\n",
        "\n"
      ],
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tweets_shape= 375\n",
            "[u'_GO', u'_EOS', u'_PAD', u'_UNK', u'\\uff01', u'\\u306e', u'\\u3066', u'0', u'\\u3001', u'\\u306b', u'\\u305f', u'\\u3067', u'\\u304c', u'\\u306f', u'\\u3092', u'\\u2026', u'\\u3057', u'\\u3002', u'\\u3082', u'#', u'\\u3067\\u3059', u'\\u307e\\u3059', u'\\u306d', u')', u'\\u3068', u'(', u'\\u306a', u'00', u'\\u306a\\u3044', u'\\u3093', u'www', u'\\u30fb', u'\\u304b\\u3089', u'\\u3060', u'\\u3088', u'\\u304b', u'\\uff1f', u'\\u307e\\u3067', u'rt', u'\\u3055\\u3093', u'\\u3054', u'\\u65e5', u'\\u62bd\\u9078', u'\\u30d5\\u30a9\\u30ed\\u30fc', u'/', u'\\u306e\\u3067', u'\\u4e2d', u'\\u3042\\u308a\\u304c\\u3068\\u3046', u'\\u6bce\\u65e5', u'\\u3059\\u308b', u'\\u671d', u'000', u'\\u03c9', u'\\u30fc', u'\\uff3c', u'\\uff0f', u'\\u540d', u'\\u69d8', u'\\u3054\\u3056\\u3044', u'\\u5f53\\u305f\\u308b', u'\\U0001f34b', u'\\u3063\\u3066', u'\\u304a', u'\\u307e\\u3057', u'\\u5fdc\\u52df', u'\\u300c', u'\\u3051\\u3069', u'\\uff06', u'\\u3053\\u306e', u'\\u6295\\u7a3f', u'\\u300d', u'w', u'\\u3042\\u3068', u'\\u305d\\u306e', u'\\u3046', u'\\u304f\\u3060\\u3055\\u3044', u'\\u3066\\u308b', u'\\u6c34', u'\\u7d50\\u679c', u'\\u3055', u'\\u301c', u'\\u307e\\u305f', u'\\u02d9', u'\\u5929\\u7136', u'\\u6311\\u6226', u'\\u4eba', u'\\u7b11', u'\\u52d5\\u753b', u'\\u79c1', u'\\u3068\\u304b', u'\\u5834', u'\\u6b8b\\u5ff5', u'\\u305f\\u3089', u'\\u30b1\\u30fc\\u30b9', u'\\u9ad8\\u3044', u'\\u3044\\u3044', u'\\u660e\\u65e5', u'\\u02d8', u'\\u30cf\\u30ba\\u30ec', u'\\u3084', u'\\u30c1\\u30e3\\u30ec\\u30f3\\u30b8', u'\\u65b0', u',', u'\\u30d7\\u30ec\\u30bc\\u30f3\\u30c8', u'\\u4eca', u'\\u308c', u'\\u5546\\u54c1', u'\\u30c6\\u30a3\\u30fc', u'\\u3059\\u3050', u'\\u4e00', u'\\uff08', u'\\u3044', u'\\u7cfb', u'\\u826f', u'\\u3061\\u3083\\u3093', u'\\u65b9', u'\\U0001f449', u'\\u306a\\u3063', u'\\uff09', u'\\U0001f453', u'\\u8a08', u'\\u610f\\u8b58', u'\\u702c', u'\\u793e\\u9577', u'\\u30e1\\u30c3\\u30bb\\u30fc\\u30b8', u'\\u305d\\u3046', u'\\u305d\\u308c', u'\\u3053\\u3068', u'\\u3060\\u3051\\u3069', u'\\U0001f622', u'\\u65e5\\u66ff\\u308f\\u308a', u'\\U0001f64f\\U0001f3fc', u'\\u2728\\uff01', u'\\u3042\\u3042', u'\\u305f\\u3044', u'\\u56de', u'\\u91d1', u'\\u3042\\u308b', u'\\u3044\\u308b', u'\\u3053\\u308c', u'\\u3088\\u3046', u'\\u4eca\\u65e5', u'-', u'\\u3054\\u89a7', u'\\u3084\\u3063', u'\\u30b9\\u30da\\u30b7\\u30e3\\u30eb', u'\\u3058\\u3083', u'\\u9ed2', u'\\u3059\\u304e', u'\\u76ee', u'\\u597d\\u304d', u'\\u3060\\u308d', u'\\u2022', u'\\u3082\\u3046', u'\\u308f', u'\\u308f\\u304b\\u308b', u'\\u304f\\u308c', u'\\u306a\\u308b', u'.', u'\\u304d', u'\\u5bdd', u':', u'\\u4f55', u'\\u6642', u'\\u6708', u'\\u3060\\u3063', u'\\u53ef\\u80fd', u'\\u3042\\u308a', u'\\u3053\\u3061\\u3089', u'\\u53ef\\u611b\\u3044', u'\\u3067\\u3082', u'\\xb4', u'\\u30d1\\u30f3\\u30c4', u'\\u3042', u'\\u3088\\u308a', u'\\u8a73\\u7d30', u'\\u3082\\u3066\\u306a\\u3057', u'\\u304a\\u9858\\u3044', u'\\u611f\\u3058', u'\\uff9f', u'\\u304f\\u308b', u'\\u3069', u'\\u306a\\u304f', u'\\u3067\\u304d\\u308b', u'\\u304f\\u3093', u'\\u306a\\u3089', u'\\u306e\\u3069\\u3054\\u3057', u'\\u30bf\\u30a4\\u30e0', u'\\u6ce2', u'\\u7460', u'\\u5b9f\\u65bd', u'\\u601d\\u3063', u'\\u4e00\\u3064', u'\\u3042\\u3063', u'\\u898b', u'\\u2661', u'\\u6765', u'\\u3057\\u304b', u'\\u2460', u'\\u2461', u'\\u671f\\u9593', u'\\u5408\\u8a08', u'\\u624b', u'`', u'\\u88fd\\u54c1', u'\\u6ef4', u'\\u6458\\u307f', u'\\u3044\\u308d\\u306f', u'\\u3059\\u3082\\u3082', u'\\u307f\\u304b\\u3093', u'\\u30ea\\u30cb\\u30e5\\u30fc\\u30a2\\u30eb', u'\\u306a\\u304b\\u3063', u'\\u51fa', u'\\u5186', u'\\u2190', u'\\u5927\\u4e08\\u592b', u'\\u307e\\u305b', u'\\u304b\\u3082', u'\\u53c2\\u52a0', u'\\u30a2\\u30ab\\u30a6\\u30f3\\u30c8', u'\\u307f', u'\\u6642\\u9593', u'\\u304f', u'\\u3070', u'\\u308c\\u308b', u'\\u2728', u'\\u65e5\\u672c', u'\\u3059', u'\\u7dbe', u'\\u3063', u'\\u524d', u'\\u0434', u'\\u601d\\u3044', u'ww', u'\\uff57', u'\\u6c17', u'\\u3060\\u3051', u'\\u3010', u'\\u30ad\\u30e3\\u30f3\\u30da\\u30fc\\u30f3', u'\\u304a\\u308a', u'\\u9df9', u'\\u3042\\u306a\\u305f', u'\\uff65', u'\\u306a\\u308a', u'\\u2192', u'\\u6295\\u7968', u'\\u30ea\\u30d7\\u30e9\\u30a4', u'\\u30b9\\u30ed\\u30c3\\u30c8', u'\\u3061\\u3083\\u3046', u'\\u3084\\u3064', u'\\u7684', u'\\u4ffa', u'\\ufe0f', u'\\u3067\\u3057', u'\\u305b', u'\\u3011', u'\\u5e74', u'\\u3048', u'\\uff5e', u'\\u3056\\u3044\\u307e\\u3059\\u3063', u'am', u'\\u8005', u'\\u304f\\u3089\\u3044', u'\\u30c4\\u30a4\\u30fc\\u30c8', u'\\u3067\\u3057\\u3087', u'\\u3069\\u3046', u'\\u307f\\u3093\\u306a', u\"'\", u'0000', u'\\u708e', u'\\u821e', u'\\u305d\\u3093\\u306a', u'\\u5165\\u308a', u'\\u30ea\\u30c4\\u30a4\\u30fc\\u30c8', u'\\u3060\\u304b\\u3089', u'\\u306a\\u3093\\u3066', u'\\u307e\\u3057\\u3087', u'\\u3088\\u308d\\u3057\\u304f', u'\\u5bb6\\u5eb7', u'\\u3082\\u3093', u'\\u753b\\u50cf', u'\\u884c\\u3063', u'cm', u'\\u306a\\u3069', u'\\u8a00\\u3063', u'\\u3061\\u3083\\u3063', u'\\u7e4b\\u304c\\u308a', u'\\u306a\\u3041', u'\\u7d76\\u8cdb', u'\\u767a\\u58f2', u'\\u3084\\u3081', u'...', u'\\u78ba\\u304b', u'\\U0001f495', u'\\u3088\\u304f', u'\\u884c\\u304f', u'\\u843d\\u3061', u'\\u81ea\\u5206', u'\\u4e07', u'\\u306e\\u306b', u'\\u3053\\u3053', u'\\u5468\\u5e74', u'\\u8a18\\u5ff5', u'\\u304a\\u5f85\\u3061', u'\\u6b21\\u56de', u'\\u76f4\\u7b46', u'\\u30b5\\u30a4\\u30f3', u'\\u30b0\\u30e9\\u30b9', u'\\u30b9\\u30da', u'\\u30b9\\u30da\\u30ad\\u30e3\\u30f3\\u30da\\u30fc\\u30f3', u'\\u98df\\u3079', u'\\u3082\\u3063\\u3068', u'\\u963f\\u90e8', u'\\u5bdb', u'\\u9854', u'\\u307f\\u305f\\u3044', u'\\u77e5\\u3063', u'\\u3078', u'\\u3067\\u308b', u'\\u307e\\u3060', u'\\u2200', u'\\u679a', u'\\ufe0e', u'\\u3053', u'\\u5f8c', u'\\u672c', u'\\u0648', u'o', u'\\u6b21', u'\\u3061\\u3087\\u3063\\u3068', u'\\u3068\\u3044\\u3046', u'\\u308f\\u305f\\u3057', u'\\u601d\\u3046', u'\\u3046\\u3093', u'\\u266a', u'\\u9811\\u5f35\\u3063', u'wwww', u'\\u307e\\u3058', u'\\u4e0a', u'\\u653e\\u6620', u'\\u4e0b\\u8a18', u'\\u751f\\u307e\\u308c', u'\\u3084\\u3093', u'\\u3067\\u304d', u'\\u6c34\\u6e90', u'\\u304a\\u3044\\u3057\\u3044', u'\\u7dcf\\u8a08', u'\\u8fd4\\u3063', u'\\u3053\\u3093\\u306a', u'\\u4e8c', u'\\u308f\\u304b\\u3089', u'\\u305f\\u304f', u'\\u8a71', u'\\u3093\\u3067', u'\\u3089\\u308c', u'\\u5fa1', u'\\u305d\\u3057\\u3066', u'\\u3064', u'\\u0325', u'\\u307b\\u3057\\u3044', u'\\u8a00\\u308f', u'\\u8003\\u3048', u'\\u305f\\u308a', u'\\u3061\\u3083', u'\\ua4aa', u'\\u3089', u'\\u3044\\u3063', u'jr', u'\\u81f4\\u3057', u'\\u4ed6', u'\\u6628\\u65e5', u'\\u300e', u'\\u300f', u'\\u9078\\u3093', u'\\u3044\\u3063\\u3071\\u3044', u'\\u5199\\u771f', u'\\u308a', u'\\u6226\\u56fd', u'\\u3057\\u304b\\u3082', u'\\u5165\\u3063', u'm', u'\\u540c\\u3058', u'\\u03b5', u'\\u4ecb\\u8b77', u'\\u3084\\u3070\\u3044', u'\\u6700\\u5f8c', u'\\u679c\\u5b9f', u'\\u30a8\\u30ad\\u30b9', u'\\u30e9\\u30b9\\u30c8\\u30b9\\u30d1\\u30fc\\u30c8', u'\\u79c0\\u5409', u'\\u5927', u'\\u7de8\\u96c6', u'\\u3057\\u3088', u'\\u4f5c\\u3063', u'\\u307e\\u3041', u'\\U0001f4a6', u'\\u5927\\u597d\\u304d', u'\\u3082\\u3089\\u3063', u'gt', u'lt', u'\\U0001f602', u'\\u3053\\u305d', u'\\u304d\\u3063\\u3068', u'\\u307e', u'\\uff57\\uff57\\uff57', u'\\u30ce', u'\\u5b09\\u3057\\u3044', u'\\u304a\\u3044', u'\\u591a\\u5206', u'\\u6570', u'(*', u'\\xba', u'\\u304a\\u8fce\\u3048', u'\\u5931\\u793c', u'\\u305e', u'\\u3046\\u308c\\u3057\\u3044', u'\\u3068\\u304d', u'\\u30c0\\u30e1', u'\\u3081\\u3063\\u3061\\u3083', u'\\u4ea4\\u63db', u'\\u4fe1\\u9577', u';', u'\\u307e\\u3044\\u308a', u'\\u305f\\u3060', u'\\u306b\\u3083', u'\\u3063\\u3059', u'\\u21db\\u2026', u'\\u306d\\u30fc', u'\\u5f53\\u9078', u'\\u4e00\\u7dd2', u'\\u306a\\u3093', u'\\u7121\\u7406', u'\\u541b', u'\\u5168\\u90e8', u'\\u8336', u'\\u3082\\u306e', u'\\u3042\\u306e', u'\\u5ea6', u'\\u5b50', u'\\uff01(', u'\\u3079', u'\\u4ed5\\u4e8b', u'\\u5bb6', u'\\u30b2\\u30fc\\u30e0', u'\\u672c\\u5f53', u'`)', u'\\u4eca\\u5e74', u'\\u25bc', u'\\u4e0b\\u3055\\u3044', u'\\u2606', u'\\u5206', u'\\u3042\\u30fc', u'\\u3048\\u3048', u'g', u'\\u306d\\u3047', u'\\u611f', u'\\u306a\\u30fc', u'\\u2605', u'\\U0001f607', u'\\u30c1\\u30a7\\u30c3\\u30af', u'\\u51fa\\u6765', u'\\u5ddd\\u8d8a', u'\\u3048\\u3063', u'\\u3055\\u3089\\u306b', u'!!', u'\\u7d50\\u69cb', u'\\u306f\\u3044', u'\\u75b2\\u308c', u'^', u'\\u65e8\\u307f', u'\\u8c4a\\u304b', u'\\u756a\\u8336', u'\\u3064\\u304b\\u3044', u'\\u5668', u'\\u624b\\u3056\\u308f\\u308a', u'\\u5473\\u308f\\u3048\\u308b', u'\\u4ed5\\u7acb\\u3066', u'\\u59ff', u'\\u8c6a\\u83ef', u'\\u7b11\\u3063', u'\\u666e\\u901a', u'\\u805e\\u3044', u'\\u52c9\\u5f37', u'(*\\xb4', u'\\u5148\\u751f', u'\\U0001f62d', u'wwwww', u'\\u8cb7\\u3063', u'\\u304b\\u3051', u'\\u8ab0', u'\\u65e9\\u304f', u'\\u62e1\\u6563', u'\\u270c', u'\\U0001f64f', u'\\u3064\\u3044', u'\\u884c\\u304d', u'\\u307e\\u307e', u'\\u3059\\u304d', u'\\u305d', u'\\u5e0c\\u671b']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9STF9lA6UVCG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 4437
        },
        "outputId": "76ed0339-bfe8-4bab-ed63-b827142f3249",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1513838035325,
          "user_tz": -540,
          "elapsed": 726,
          "user": {
            "displayName": "Taro Minowa",
            "photoUrl": "//lh6.googleusercontent.com/-G-LK6tJKdI8/AAAAAAAAAAI/AAAAAAACNIM/dpIvfwO7Jmg/s50-c-k-no/photo.jpg",
            "userId": "107321843635318237808"
          }
        }
      },
      "source": [
        "sess = tf.Session()\n",
        "# Note that tweets data should be a matrix where each line has exact same length.\n",
        "tweets_dataset = tf.data.Dataset.from_tensor_slices(tweets)\n",
        "replies_dataset = tf.data.Dataset.from_tensor_slices(replies)\n",
        "\n",
        "tweets_transposed = tweets_dataset.batch(real_hparams.batch_size).map(lambda x: tf.transpose(x))\n",
        "replies_with_eos_suffix = replies_dataset.map(lambda x: tf.concat([x, [tgt_eos_id]], axis=0)).batch(real_hparams.batch_size)\n",
        "replies_with_sos_prefix = replies_dataset.map(lambda x: tf.concat([[tgt_sos_id], x], axis=0)).batch(real_hparams.batch_size).map(lambda x: tf.transpose(x))\n",
        "\n",
        "print(\"tweets_example:\", sess.run(tweets_transposed.make_one_shot_iterator().get_next()))\n",
        "print(\"reply_with_eos_suffix_example:\", sess.run(replies_with_eos_suffix.make_one_shot_iterator().get_next()))\n",
        "print(\"reply_with_sos_prefix_example:\", sess.run(replies_with_sos_prefix.make_one_shot_iterator().get_next()))\n",
        "\n",
        "# Merge all using zip\n",
        "train_feed_data = tf.data.Dataset.zip((tweets_transposed, replies_with_eos_suffix, replies_with_sos_prefix))\n",
        "train_feed_data_value = sess.run(train_feed_data.make_one_shot_iterator().get_next())\n",
        "print(\"train_feed_data=\", train_feed_data_value[0])\n",
        "print(\"train_feed_data=\", train_feed_data_value[1])\n",
        "print(\"train_feed_data=\", train_feed_data_value[2])                                 \n",
        "                                 "
      ],
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tweets_example: [[  3   3   3  25   3   3  54   3  54   3  19  54   3   3  54   3   3  54\n",
            "    3   3  54  54   3  54  54]\n",
            " [  3   3   3   3   3   6  72  73 388 146 389  72 114  20  42   3  14  42\n",
            "   17   3  42  73  14 388  72]\n",
            " [ 49  28  10   3 197   3   7   3   4 182   5   7 479   2  78   3 480  78\n",
            "    3 392  78  90   3   4   7]\n",
            " [185  26 424   3  28  26  41  15  72   6 176  41  10   2  12   3   9  12\n",
            "   39  74  12  11   4  72  41]\n",
            " [  3   3   2   3 425  45 119   4   7   3  13 119 110   2 246 231 310 246\n",
            "    9  35 246  59 274   7 119]\n",
            " [ 89   7   2   3  22   3   4   4  41  26   3   4  86   2  11   3   3  11\n",
            "    3  24  11   4  22  41   4]\n",
            " [  5 229   2 110  15   6  55   2  55   4 478  55 118   2 108   3   6 108\n",
            "   16 191 108  72  15  55  55]\n",
            " [  3  23   2   3   2  18  83   2  43   4   4  83 310   2 155  15  10 155\n",
            "    6  10 155   7  17  43  83]\n",
            " [  3 144   2  11   2 215  77   2  67   4   3  77   9   2  55   2  32  55\n",
            "    3  66  55  41   3  67  77]\n",
            " [290   6   2 144   2  35  32   2  38   3   5  32 159   2  48   2   8  48\n",
            "   63   3  48  55  28  38  32]\n",
            " [ 53  92   2   6   2  24   5   2  11   3   3   5   6   2  84   2 126  84\n",
            "   10 197  84  43  34  11   5]\n",
            " [ 99   3   2   3   2  15 101   2  65   3  14 101  34   2 183   2 481 183\n",
            "   17 427 183  67  22  65 101]\n",
            " [ 71  80   2  12   2 229 106   2 186  13   3 106 110   2  65   2   6  65\n",
            "    3 342  65  38  15 186 106]\n",
            " [  2   4   2   3   2   4  19   2 145   3  16  19  86   2 136   2   3 136\n",
            "   89   2 136  11  17 145  19]\n",
            " [  2   2   2  39   2   3  50   2 187 125   8  50 118   2 147   2   3 147\n",
            "    3   2 147  65   3 187  50]\n",
            " [  2   2   2   5   2  33 107   2  70  33   3 107   2   2 247   2   3 247\n",
            "   13   2 247 186 248  70 107]\n",
            " [  2   2   2 230   2  24   7   2  12  32  85   7   2   2  70   2  74  70\n",
            "    3   2  70 145   3  12   7]\n",
            " [  2   2   2  11   2   3  93   2  42 167   9  93   2   2 190   2  61 190\n",
            "    8   2 190 187   4  42  93]\n",
            " [  2   2   2   3   2 216  12   2  11   4   3  12   2   2  46   2   3  46\n",
            "  482   2  46  70   4  11  12]\n",
            " [  2   2   2  49   2  29  73   2  59   2 218  73   2   2   4   2  63   4\n",
            "   46   2   4  12   4  59  73]]\n",
            "reply_with_eos_suffix_example: [[  3  16  21  30   3   3  36   4   5 115  12   3  49   2   2   2   2   2\n",
            "    2   1]\n",
            " [  3 333 229  25   3   3   3  23   2   2   2   2   2   2   2   2   2   2\n",
            "    2   1]\n",
            " [  3   3  92   3   3  49 424  29   2   2   2   2   2   2   2   2   2   2\n",
            "    2   1]\n",
            " [331   5   3   3   3   9   3   3   3  82  23   2   2   2   2   2   2   2\n",
            "    2   1]\n",
            " [193   3 153   3  12 138 353  30   2   2   2   2   2   2   2   2   2   2\n",
            "    2   1]\n",
            " [  3   8   9   3   3  39   9   3   3  79 224  89   3   3  25  97  52  97\n",
            "   23   1]\n",
            " [ 40  64  47  58  21  60   4 128  91  31  31  31  98  20 129   4   7  44\n",
            "   27   1]\n",
            " [  3   3 158 158 158 195   3   3  49 163   9  88  18   3 232 134   2   2\n",
            "    2   1]\n",
            " [ 91   8  81   5  40  64  14 303  16   6 239  21  17 304  18 100  75   4\n",
            "  186   1]\n",
            " [126 456   3  61   3   6  10 299   3  10 154   3  24   3   5   3  16   6\n",
            "   10   1]\n",
            " [ 19 389   5 176  14 373  33 241  13   3  26 115  20  22   4 271 241   9\n",
            "    8   1]\n",
            " [ 40  64  47  58  21  60   4 128  91  31  31  31  98  20 129   4   7  44\n",
            "   27   1]\n",
            " [  3   3 154   4   4   3   3 229  35  26   2   2   2   2   2   2   2   2\n",
            "    2   1]\n",
            " [  3   8   3 425  35   3  89   3 185   3   5   3  89  18   3  49   5  12\n",
            "    3   1]\n",
            " [ 40  64  47  40 259   4  42  78  13   8 168   5  87  14 143  75   4   7\n",
            "  164   1]\n",
            " [  3  39   3  12   3   5  35  26  25  97  52  97  23   3  15   2   2   2\n",
            "    2   1]\n",
            " [266   3  34   8   3   3   5   3   3  17   2   2   2   2   2   2   2   2\n",
            "    2   1]\n",
            " [ 40  64  47  40 259   4  42  78  13   8 168   5  87  14 143  75   4   7\n",
            "  164   1]\n",
            " [160 296   3   9   3  16   6  10  29  33  32  22   4   4   4   4  22   4\n",
            "   36   1]\n",
            " [ 62   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2\n",
            "    2   1]\n",
            " [ 40  64  47  40 259   4  42  78  13   8 168   5  87  14 143  75   4   7\n",
            "  164   1]\n",
            " [ 91   8  81   5  40  64  14 303  16   6 239  21  17 304  18 100  75   4\n",
            "  186   1]\n",
            " [ 79   8   3 134  12   3  18   3 410   3  23  71   3   3   3   3   5   3\n",
            "  137   1]\n",
            " [ 91   8  81   5  40  64  14 303  16   6 239  21  17 304  18 100  75   4\n",
            "  186   1]\n",
            " [ 40  64  47  58  21  60   4 128  91  31  31  31  98  20 129   4   7  44\n",
            "   27   1]]\n",
            "reply_with_sos_prefix_example: [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0]\n",
            " [  3   3   3 331 193   3  40   3  91 126  19  40   3   3  40   3 266  40\n",
            "  160  62  40  91  79  91  40]\n",
            " [ 16 333   3   5   3   8  64   3   8 456 389  64   3   8  64  39   3  64\n",
            "  296   2  64   8   8   8  64]\n",
            " [ 21 229  92   3 153   9  47 158  81   3   5  47 154   3  47   3  34  47\n",
            "    3   2  47  81   3  81  47]\n",
            " [ 30  25   3   3   3   3  58 158   5  61 176  58   4 425  40  12   8  40\n",
            "    9   2  40   5 134   5  58]\n",
            " [  3   3   3   3  12   3  21 158  40   3  14  21   4  35 259   3   3 259\n",
            "    3   2 259  40  12  40  21]\n",
            " [  3   3  49   9 138  39  60 195  64   6 373  60   3   3   4   5   3   4\n",
            "   16   2   4  64   3  64  60]\n",
            " [ 36   3 424   3 353   9   4   3  14  10  33   4   3  89  42  35   5  42\n",
            "    6   2  42  14  18  14   4]\n",
            " [  4  23  29   3  30   3 128   3 303 299 241 128 229   3  78  26   3  78\n",
            "   10   2  78 303   3 303 128]\n",
            " [  5   2   2   3   2   3  91  49  16   3  13  91  35 185  13  25   3  13\n",
            "   29   2  13  16 410  16  91]\n",
            " [115   2   2  82   2  79  31 163   6  10   3  31  26   3   8  97  17   8\n",
            "   33   2   8   6   3   6  31]\n",
            " [ 12   2   2  23   2 224  31   9 239 154  26  31   2   5 168  52   2 168\n",
            "   32   2 168 239  23 239  31]\n",
            " [  3   2   2   2   2  89  31  88  21   3 115  31   2   3   5  97   2   5\n",
            "   22   2   5  21  71  21  31]\n",
            " [ 49   2   2   2   2   3  98  18  17  24  20  98   2  89  87  23   2  87\n",
            "    4   2  87  17   3  17  98]\n",
            " [  2   2   2   2   2   3  20   3 304   3  22  20   2  18  14   3   2  14\n",
            "    4   2  14 304   3 304  20]\n",
            " [  2   2   2   2   2  25 129 232  18   5   4 129   2   3 143  15   2 143\n",
            "    4   2 143  18   3  18 129]\n",
            " [  2   2   2   2   2  97   4 134 100   3 271   4   2  49  75   2   2  75\n",
            "    4   2  75 100   3 100   4]\n",
            " [  2   2   2   2   2  52   7   2  75  16 241   7   2   5   4   2   2   4\n",
            "   22   2   4  75   5  75   7]\n",
            " [  2   2   2   2   2  97  44   2   4   6   9  44   2  12   7   2   2   7\n",
            "    4   2   7   4   3   4  44]\n",
            " [  2   2   2   2   2  23  27   2 186  10   8  27   2   3 164   2   2 164\n",
            "   36   2 164 186 137 186  27]]\n",
            "train_feed_data= [[  3   3   3  25   3   3  54   3  54   3  19  54   3   3  54   3   3  54\n",
            "    3   3  54  54   3  54  54]\n",
            " [  3   3   3   3   3   6  72  73 388 146 389  72 114  20  42   3  14  42\n",
            "   17   3  42  73  14 388  72]\n",
            " [ 49  28  10   3 197   3   7   3   4 182   5   7 479   2  78   3 480  78\n",
            "    3 392  78  90   3   4   7]\n",
            " [185  26 424   3  28  26  41  15  72   6 176  41  10   2  12   3   9  12\n",
            "   39  74  12  11   4  72  41]\n",
            " [  3   3   2   3 425  45 119   4   7   3  13 119 110   2 246 231 310 246\n",
            "    9  35 246  59 274   7 119]\n",
            " [ 89   7   2   3  22   3   4   4  41  26   3   4  86   2  11   3   3  11\n",
            "    3  24  11   4  22  41   4]\n",
            " [  5 229   2 110  15   6  55   2  55   4 478  55 118   2 108   3   6 108\n",
            "   16 191 108  72  15  55  55]\n",
            " [  3  23   2   3   2  18  83   2  43   4   4  83 310   2 155  15  10 155\n",
            "    6  10 155   7  17  43  83]\n",
            " [  3 144   2  11   2 215  77   2  67   4   3  77   9   2  55   2  32  55\n",
            "    3  66  55  41   3  67  77]\n",
            " [290   6   2 144   2  35  32   2  38   3   5  32 159   2  48   2   8  48\n",
            "   63   3  48  55  28  38  32]\n",
            " [ 53  92   2   6   2  24   5   2  11   3   3   5   6   2  84   2 126  84\n",
            "   10 197  84  43  34  11   5]\n",
            " [ 99   3   2   3   2  15 101   2  65   3  14 101  34   2 183   2 481 183\n",
            "   17 427 183  67  22  65 101]\n",
            " [ 71  80   2  12   2 229 106   2 186  13   3 106 110   2  65   2   6  65\n",
            "    3 342  65  38  15 186 106]\n",
            " [  2   4   2   3   2   4  19   2 145   3  16  19  86   2 136   2   3 136\n",
            "   89   2 136  11  17 145  19]\n",
            " [  2   2   2  39   2   3  50   2 187 125   8  50 118   2 147   2   3 147\n",
            "    3   2 147  65   3 187  50]\n",
            " [  2   2   2   5   2  33 107   2  70  33   3 107   2   2 247   2   3 247\n",
            "   13   2 247 186 248  70 107]\n",
            " [  2   2   2 230   2  24   7   2  12  32  85   7   2   2  70   2  74  70\n",
            "    3   2  70 145   3  12   7]\n",
            " [  2   2   2  11   2   3  93   2  42 167   9  93   2   2 190   2  61 190\n",
            "    8   2 190 187   4  42  93]\n",
            " [  2   2   2   3   2 216  12   2  11   4   3  12   2   2  46   2   3  46\n",
            "  482   2  46  70   4  11  12]\n",
            " [  2   2   2  49   2  29  73   2  59   2 218  73   2   2   4   2  63   4\n",
            "   46   2   4  12   4  59  73]]\n",
            "train_feed_data= [[  3  16  21  30   3   3  36   4   5 115  12   3  49   2   2   2   2   2\n",
            "    2   1]\n",
            " [  3 333 229  25   3   3   3  23   2   2   2   2   2   2   2   2   2   2\n",
            "    2   1]\n",
            " [  3   3  92   3   3  49 424  29   2   2   2   2   2   2   2   2   2   2\n",
            "    2   1]\n",
            " [331   5   3   3   3   9   3   3   3  82  23   2   2   2   2   2   2   2\n",
            "    2   1]\n",
            " [193   3 153   3  12 138 353  30   2   2   2   2   2   2   2   2   2   2\n",
            "    2   1]\n",
            " [  3   8   9   3   3  39   9   3   3  79 224  89   3   3  25  97  52  97\n",
            "   23   1]\n",
            " [ 40  64  47  58  21  60   4 128  91  31  31  31  98  20 129   4   7  44\n",
            "   27   1]\n",
            " [  3   3 158 158 158 195   3   3  49 163   9  88  18   3 232 134   2   2\n",
            "    2   1]\n",
            " [ 91   8  81   5  40  64  14 303  16   6 239  21  17 304  18 100  75   4\n",
            "  186   1]\n",
            " [126 456   3  61   3   6  10 299   3  10 154   3  24   3   5   3  16   6\n",
            "   10   1]\n",
            " [ 19 389   5 176  14 373  33 241  13   3  26 115  20  22   4 271 241   9\n",
            "    8   1]\n",
            " [ 40  64  47  58  21  60   4 128  91  31  31  31  98  20 129   4   7  44\n",
            "   27   1]\n",
            " [  3   3 154   4   4   3   3 229  35  26   2   2   2   2   2   2   2   2\n",
            "    2   1]\n",
            " [  3   8   3 425  35   3  89   3 185   3   5   3  89  18   3  49   5  12\n",
            "    3   1]\n",
            " [ 40  64  47  40 259   4  42  78  13   8 168   5  87  14 143  75   4   7\n",
            "  164   1]\n",
            " [  3  39   3  12   3   5  35  26  25  97  52  97  23   3  15   2   2   2\n",
            "    2   1]\n",
            " [266   3  34   8   3   3   5   3   3  17   2   2   2   2   2   2   2   2\n",
            "    2   1]\n",
            " [ 40  64  47  40 259   4  42  78  13   8 168   5  87  14 143  75   4   7\n",
            "  164   1]\n",
            " [160 296   3   9   3  16   6  10  29  33  32  22   4   4   4   4  22   4\n",
            "   36   1]\n",
            " [ 62   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2\n",
            "    2   1]\n",
            " [ 40  64  47  40 259   4  42  78  13   8 168   5  87  14 143  75   4   7\n",
            "  164   1]\n",
            " [ 91   8  81   5  40  64  14 303  16   6 239  21  17 304  18 100  75   4\n",
            "  186   1]\n",
            " [ 79   8   3 134  12   3  18   3 410   3  23  71   3   3   3   3   5   3\n",
            "  137   1]\n",
            " [ 91   8  81   5  40  64  14 303  16   6 239  21  17 304  18 100  75   4\n",
            "  186   1]\n",
            " [ 40  64  47  58  21  60   4 128  91  31  31  31  98  20 129   4   7  44\n",
            "   27   1]]\n",
            "train_feed_data= [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0]\n",
            " [  3   3   3 331 193   3  40   3  91 126  19  40   3   3  40   3 266  40\n",
            "  160  62  40  91  79  91  40]\n",
            " [ 16 333   3   5   3   8  64   3   8 456 389  64   3   8  64  39   3  64\n",
            "  296   2  64   8   8   8  64]\n",
            " [ 21 229  92   3 153   9  47 158  81   3   5  47 154   3  47   3  34  47\n",
            "    3   2  47  81   3  81  47]\n",
            " [ 30  25   3   3   3   3  58 158   5  61 176  58   4 425  40  12   8  40\n",
            "    9   2  40   5 134   5  58]\n",
            " [  3   3   3   3  12   3  21 158  40   3  14  21   4  35 259   3   3 259\n",
            "    3   2 259  40  12  40  21]\n",
            " [  3   3  49   9 138  39  60 195  64   6 373  60   3   3   4   5   3   4\n",
            "   16   2   4  64   3  64  60]\n",
            " [ 36   3 424   3 353   9   4   3  14  10  33   4   3  89  42  35   5  42\n",
            "    6   2  42  14  18  14   4]\n",
            " [  4  23  29   3  30   3 128   3 303 299 241 128 229   3  78  26   3  78\n",
            "   10   2  78 303   3 303 128]\n",
            " [  5   2   2   3   2   3  91  49  16   3  13  91  35 185  13  25   3  13\n",
            "   29   2  13  16 410  16  91]\n",
            " [115   2   2  82   2  79  31 163   6  10   3  31  26   3   8  97  17   8\n",
            "   33   2   8   6   3   6  31]\n",
            " [ 12   2   2  23   2 224  31   9 239 154  26  31   2   5 168  52   2 168\n",
            "   32   2 168 239  23 239  31]\n",
            " [  3   2   2   2   2  89  31  88  21   3 115  31   2   3   5  97   2   5\n",
            "   22   2   5  21  71  21  31]\n",
            " [ 49   2   2   2   2   3  98  18  17  24  20  98   2  89  87  23   2  87\n",
            "    4   2  87  17   3  17  98]\n",
            " [  2   2   2   2   2   3  20   3 304   3  22  20   2  18  14   3   2  14\n",
            "    4   2  14 304   3 304  20]\n",
            " [  2   2   2   2   2  25 129 232  18   5   4 129   2   3 143  15   2 143\n",
            "    4   2 143  18   3  18 129]\n",
            " [  2   2   2   2   2  97   4 134 100   3 271   4   2  49  75   2   2  75\n",
            "    4   2  75 100   3 100   4]\n",
            " [  2   2   2   2   2  52   7   2  75  16 241   7   2   5   4   2   2   4\n",
            "   22   2   4  75   5  75   7]\n",
            " [  2   2   2   2   2  97  44   2   4   6   9  44   2  12   7   2   2   7\n",
            "    4   2   7   4   3   4  44]\n",
            " [  2   2   2   2   2  23  27   2 186  10   8  27   2   3 164   2   2 164\n",
            "   36   2 164 186 137 186  27]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dagyd_fKE8lX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 7
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "999deee9-5fc4-417e-8a59-c4da2a1a196f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1513838083082,
          "user_tz": -540,
          "elapsed": 41332,
          "user": {
            "displayName": "Taro Minowa",
            "photoUrl": "//lh6.googleusercontent.com/-G-LK6tJKdI8/AAAAAAAAAAI/AAAAAAACNIM/dpIvfwO7Jmg/s50-c-k-no/photo.jpg",
            "userId": "107321843635318237808"
          }
        }
      },
      "source": [
        "# Train using real data.\n",
        "#! rm -rf ./saved_model/real\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "graph3= tf.Graph()\n",
        "with graph3.as_default():\n",
        "  sess3 = tf.Session(graph=graph3)\n",
        "  model3 = ChatbotModel(sess3, real_hparams, model_path=\"./saved_model/real\")\n",
        "  train_data_iterator = train_feed_data.repeat(1000).shuffle(500000).make_one_shot_iterator()\n",
        "    \n",
        "  for i in range(10): # real_hparams.num_train_steps):\n",
        "    train_data = sess3.run(train_data_iterator.get_next())\n",
        "    loss_value, global_step = model3.train(train_data[0], train_data[1], train_data[2], np.ones((real_hparams.batch_size), dtype=int) * real_hparams.decoder_length)\n",
        "\n",
        "    if i % 5 == 0 and real_hparams.debug_verbose:\n",
        "      print('.', end='')\n",
        "\n",
        "    if i % 15 == 0:\n",
        "      model3.save()\n",
        "      x.append(global_step)\n",
        "      y.append(loss_value)\n",
        "      if real_hparams.debug_verbose:\n",
        "        print(\"loss={} step={}\".format(loss_value, global_step))\n",
        "\n",
        "  # Calculate log_prob of www and \n",
        "  train_data = sess3.run(train_data_iterator.get_next())\n",
        "  print(\"probablity of www\", model3.log_prob(train_data[0], [vocab['www']]))\n",
        "  print(\"probablity of 00\", model3.log_prob(train_data[0], [vocab['00']]))\n",
        "\n"
      ],
      "cell_type": "code",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rnn_output.shape= (25, ?, 500)\n",
            "sample_id.shape= (25, ?)\n",
            "final_state= LSTMStateTuple(c=<tf.Tensor 'decoder/while/Exit_3:0' shape=(25, 1024) dtype=float32>, h=<tf.Tensor 'decoder/while/Exit_4:0' shape=(25, 1024) dtype=float32>)\n",
            "final_sequence_lengths.shape= (25,)\n",
            "created fresh model.\n",
            ".loss=124.389694214 step=1\n",
            ".probablity of www -8.21092362232\n",
            "probablity of 00 -8.77094587006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y4auRWoHk9RW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "972fbee5-293d-4e7e-86f5-a06e5849f31c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1513838083767,
          "user_tz": -540,
          "elapsed": 631,
          "user": {
            "displayName": "Taro Minowa",
            "photoUrl": "//lh6.googleusercontent.com/-G-LK6tJKdI8/AAAAAAAAAAI/AAAAAAACNIM/dpIvfwO7Jmg/s50-c-k-no/photo.jpg",
            "userId": "107321843635318237808"
          }
        }
      },
      "source": [
        "\n",
        "plt.plot(x, y, label=\"Loss\")\n",
        "plt.plot()\n",
        "\n",
        "plt.xlabel(\"Loss\")\n",
        "plt.ylabel(\"steps\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFYCAYAAACoFn5YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZgi8x4YAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f12fa1e4110>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "FsvxQU26XsOd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 2
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0f0574a3-4d29-4b10-bbd3-cfffc6c97857",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1513838086473,
          "user_tz": -540,
          "elapsed": 2540,
          "user": {
            "displayName": "Taro Minowa",
            "photoUrl": "//lh6.googleusercontent.com/-G-LK6tJKdI8/AAAAAAAAAAI/AAAAAAACNIM/dpIvfwO7Jmg/s50-c-k-no/photo.jpg",
            "userId": "107321843635318237808"
          }
        }
      },
      "source": [
        "with graph3.as_default():\n",
        "  inference_encoder_inputs = np.empty((real_hparams.encoder_length, real_hparams.batch_size), dtype=np.int)\n",
        "  tweet = [\"フォロー\", \"ありがとう\", \"メッセージ\", \"😢\", \"www\"]\n",
        "  tweet_ids = words_to_ids(tweet, vocab)\n",
        "  tweet_ids.extend([pad_id] * (real_hparams.encoder_length - len(tweet_ids)))\n",
        "  for i in range(real_hparams.batch_size):\n",
        "    inference_encoder_inputs[:, i] = np.array(tweet_ids, dtype=np.int) \n",
        "\n",
        "  replies = model3.infer(inference_encoder_inputs)\n",
        "  reply = replies[0].tolist()\n",
        "  print(\"Infered reply\", ids_to_words(reply, rev_vocab))\n",
        "  \n",
        "  beam_replies = model3.infer_beam_search(inference_encoder_inputs)\n",
        "  print(\"Infered replies candidate0\", ids_to_words(beam_replies[0][:,0], rev_vocab))\n",
        "  print(\"Infered replies candidate1\", ids_to_words(beam_replies[0][:,1], rev_vocab))"
      ],
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Infered reply _UNK_UNK_UNK_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_EOS\n",
            "Infered replies candidate0 _UNK_UNK_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_EOS_EOS\n",
            "Infered replies candidate1 _UNK_UNK_UNK_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_PAD_EOS_EOS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y0JPF6FUb3Af",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "source": [
        "|"
      ],
      "cell_type": "code",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LaRoq9XrxTk2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "source": [
        ""
      ],
      "cell_type": "code",
      "execution_count": 0,
      "outputs": []
    }
  ]
}
